[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Supplementary Notes for ECE 2714: Signals and Systems",
    "section": "",
    "text": "About the Notes\nThis is a set of supplementary notes and examples for ECE 2714 in the Bradley Department of Electrical and Computer Engineering at Virginia Tech.",
    "crumbs": [
      "About the Notes"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Supplementary Notes for ECE 2714: Signals and Systems",
    "section": "License",
    "text": "License\nThis work is licensed under a Creative Commons Attribution 4.0 International License.",
    "crumbs": [
      "About the Notes"
    ]
  },
  {
    "objectID": "index.html#update-history",
    "href": "index.html#update-history",
    "title": "Supplementary Notes for ECE 2714: Signals and Systems",
    "section": "Update History",
    "text": "Update History\nThis book is continually updated as new content becomes available and errata corrected.\n\nJune 2025: Conversion of Chapter 1 complete.\nFeb 2025: Conversion from LaTeX pdf to accessible html started.",
    "crumbs": [
      "About the Notes"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "To the student:\nThis is a set of supplementary notes and examples for ECE 2714. It is not a replacement for the textbook, but can act as a reference and guide your reading. These notes are not comprehensive – often additional material and insights are covered during class.\nThis material is well covered in the official course text “Oppenheim, A. V., Willsky, A. S., and Nawab, S. H. Signals and Systems. ii, Essex UK: Prentice Hall Pearson, 1996.” (abbreviated OW). This is an older, but very good book. However there are many, many texts that cover the same material. reading a textbook is one of the most important things you can do to learn this material. Again, these notes should be considered a replacement for a textbook.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#to-the-instructor",
    "href": "preface.html#to-the-instructor",
    "title": "Preface",
    "section": "To the instructor:",
    "text": "To the instructor:\nThese notes are simply a way to provide some consistency in topic coverage and notation between and within semesters. Feel free to share these with your class but you are under no obligation to do so. There are many alternative ways to motivate and develop this material and you should use the way that you like best. This is just how I do it.\nEach chapter corresponds to a “Topic Learning Objective” and would typically be covered in one class meeting on a Tuesday-Thursday or Monday-Wednesday schedule. Note CT and DT topics are taught interleaved rather than in separate blocks. This gets the student used to going back and forth between the two signal and system types. We introduce time-domain topics first, followed by (real) frequency domain topics, using complex frequency domain for sinusoidal analysis only and as a bridge. Detailed analysis and application of Laplace and Z-transforms is left to ECE 3704.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#acknowledgements",
    "href": "preface.html#acknowledgements",
    "title": "Preface",
    "section": "Acknowledgements:",
    "text": "Acknowledgements:\nThe development of this course has been, and continues to be, a team effort. Dr. Mike Buehrer was instrumental in the initial design and roll-out of the course. Dr. Mary Lanzerotti has helped enormously with the course organization and academic integrity. All the instructors thus far: Drs. Buehrer, Safaai-Jazi, Lanzerotti, Kekatos, Poon, Xu, and Talty, have shaped the course in some fashion.\n\nC.L. Wyatt\nMay 7, 2024",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  Course Introduction",
    "section": "",
    "text": "1.1 Example Signals and Systems\nThe concepts and techniques in this course are probably the most useful in engineering. A signal is a function of one or more independent variables conveying information about a physical (or virtual) phenomena. A system may respond to signals to produce other signals, or produce signals directly.\nThis course is about the mathematical models and related techniques for the design and understanding of systems as signal transformations. We focus on a broadly useful class of systems, known as linear, time-invariant systems. You will learn about:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#example-signals-and-systems",
    "href": "01-intro.html#example-signals-and-systems",
    "title": "1  Course Introduction",
    "section": "",
    "text": "Example\n\n\nElectrical Circuits. This is a Sallen-Key filter, a second-order system commonly use to select frequencies from a signal:\n\nThere are two signals we can easily identify, the input signal as the voltage applied across x(t)x(t), and the output voltage measured across y(t)y(t). We build on your circuits course by viewing this circuit as an implementation of a more abstract linear system. We see how it can be viewed as a frequency selective filter. We will see how to answer questions such as: how do we choose the values of the resistors and capacitors to select the frequencies we are interested in? and how do we determine what those frequencies are?\n\n\n\n\nExample\n\n\nRobotic Joint. This is a Linear, Time-Invariant model of a DC motor, a mixture of electrical and mechanical components.\n\nHow do we convert the motor into a servo for use in a robotic joint? What are its characteristics (e.g. how fast can it move)?\n\n\n\n\nExample\n\n\nAudio Processing. Suppose you record an interview for a podcast, but during an important part of the discussion, the HVAC turns on and there is an annoying noise in the background.\n\nHow could you remove the noise minimizing distortion to the rest of the audio?\n\n\n\n\nExample\n\n\nCommunications. Consider a wireless sensor, that needs to transmit to a base station, e.g. a wireless mic system.\n\nHow should the signal be processed so it can be transmitted? How should the received signal be processed?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#types-of-problems",
    "href": "01-intro.html#types-of-problems",
    "title": "1  Course Introduction",
    "section": "1.2 Types of Problems",
    "text": "1.2 Types of Problems\nApplications of this material occur in all areas of science and engineering. When we have a measured output but are unsure what combination of inputs and system components could have produced it, we have a modeling problem.\n\nModels are the bedrock of the scientific method and are required to apply the concepts of this course to engineering problems.\nWhen we know the input and the system description and desire to know the output we have an analysis problem.\n\nAnalysis problems are the kind you have encountered most often already. For example, given an electrical circuit and an applied voltage or current, what are the voltages and currents across and through the various components.\nWhen we know either the input and desired output and seek the system to perform this transformation,\n\nor we know the system description and output and desire the input that would generate the output,\n\nwe have a design problem.\nThis course focuses on modeling and analysis with applications to electrical circuits and devices for measurement and control of the physical world and is broadly applicable to all ECE majors. Some Examples:\n\nControls, Robotics, & Autonomy: LTI systems theory forms the basis of perception and control of machines.\nCommunications & Networking: LTI systems theory forms the basis of transmission and reception of signals, e.g. AM and FM radio.\nMachine Learning: LTI systems are often used to pre-process samples or to create basis functions to improve learning.\nEnergy & Power Electronic Systems: linear circuits are often modeled as LTI systems.\n\nSubsequent courses, e.g. ECE 3704, focus more on analysis and design.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#learning-objectives",
    "href": "01-intro.html#learning-objectives",
    "title": "1  Course Introduction",
    "section": "1.3 Learning Objectives",
    "text": "1.3 Learning Objectives\nThe learning objectives (LOs) for the course are:\n\nDescribe a given system using a block-level description and identify the input/output signals.\nMathematically model continuous and discrete linear, time-invariant systems using differential and difference equations respectively.\nAnalyze the use of filters and their interpretation in the time and frequency domains and implement standard filters in hardware and/or software.\nApply computations of the four fundamental Fourier transforms to the analysis and design of linear systems.\nCommunicate solutions to problems and document projects within the domain of signals and systems through formal written documents.\n\nThese are broken down further into the following topic learning objectives (TLOs). The TLOs generally map onto one class meeting but are used extensively in later TLOs.\n\nCourse introduction (OW Forward and §1.0)\n\nSignals as models\nSystems as transformation of signals\nPrerequisites\n\nContinuous-time (CT) signals (OW §1.1 through 1.4 and 2.5): A continuous-time (CT) signal is a function of one or more independent variables conveying information about a physical phenomena. This lecture gives an introduction to continuous-time signals as functions. You learn how to characterize such signals in a number of ways and are introduced to two very important signals: the unit impulse and the complex exponential.\n\nContinuous-time signals as functions ℝ↦ℂ\\mathbb{R}\\mapsto\\mathbb{C}\nTransformations of time\nCharacterizing signals\n\nperiodic/aperiodic\neven/odd\nenergy or/nor power\n\nImpulse function\nStep function\nComplex exponential\n\nDiscrete-time (DT) signals (OW §1.1 through 1.4)\n\nDiscrete-time signals as functions ℤ↦ℂ\\mathbb{Z}\\mapsto\\mathbb{C}\nTransformations of time index\nCharacterizing signals\n\nperiodic/aperiodic\neven/odd\nenergy or/nor power\n\nImpulse function\nStep function\nComplex exponential\n\nCT systems as linear constant coefficient differential equations (OW §2.4.1)\n\nLCCDE and their solution (1st and 2nd order)\nimpulse response from LCCDE\n\nDT systems as linear constant coefficient difference equations (OW §2.4.2)\n\nLCCDE and their solution (1st and 2nd order)\nimpulse response from LCCDE\n\nLinear time invariant CT systems (OW §1.5, 1.6, 2.3)\n\nMemory\nInvertability\nCausality\nStability\nTime-invariance\nLinearity\nDefine LTI system\n\nLinear time invariant DT systems (OW §1.5, 1.6, 2.3)\n\nMemory\nInvertability\nCausality\nStability\nTime-invariance\nLinearity\nDefine LTI system\n\nCT convolution (OW §2.2)\n\nReview CT LTI systems and superposition property\nCT Convolution Integral\nProperties of convolution\n\ncommunative\ndistributive\nassociative\n\nDetermining system response using convolution with impulse response\n\nDT convolution (OW §2.1)\n\nReview DT LTI systems and superposition property\nDT Convolution Sum\nProperties of convolution\n\ncommunative\ndistributive\nassociative\n\nDetermining system response using convolution with impulse response\n\nCT block diagrams (OW §1.5.2 and 2.4.3)\n\nblocks represented by impulse response\nseries and parallel connections, reductions\nscale, sum, and integrator blocks\nequivalence of LCCDE’s and block diagrams\nfirst-order differential equation as feedback motif\nsecond-order differential equation as a feedback motif\nimplementing a LCCDE using adders, multipliers, and integrators\n\nDT block diagrams (OW §1.5.2 and 2.4.3)\n\nblocks represented by impulse response\nseries and parallel connections, reductions\nscale, sum, and unit delay blocks\nequivalence of LCCDE’s and block diagrams\nfirst-order difference equation as feedback motif\nsecond-order difference equation as a feedback motif\nimplementing a LCCDE using adders, multipliers, and delays\n\nEigenfunctions of CT systems (OW §3.2 and 3.8)\n\nEigenfunction este^{st}\nTransfer Function H(s)H(s)\nStability and Frequency Response (FR) H(jω)H(j\\omega)\nHow this is useful - decomposition of input signal into complex exp\nWhat signals can be decomposed this way, foreshadow Fourier Analysis\n\nEigenfunctions of DT systems (OW §3.2 and 3.8)\n\nEigenfunction znz^{n}\nTransfer Function H(z)H(z)\nStability and Frequency Response (FR) H(ejω)H\\left(e^{j\\omega}\\right)\nHow this is useful - decomposition of input signal into complex exp\nWhat signals can be decomposed this way, foreshadow Fourier Analysis\n\nCT Fourier Series representation of signals (OW §3.3 through 3.5)\n\nreview CT periodic functions\nharmonic sums\nderive synthesis equation\nderive analysis equation\nspectrum plots\ndefine mean-square convergence\ntruncated CT FS\nstable LTI system response using CTFS\nexample of the impulse train (for sampling theory later)\nformal Dirichlet conditions\nproperties of CT FS\n\nDT Fourier Series representation of signals (OW §3.6 and 3.7)\n\nreview DT periodic functions\nharmonic sums\nderive synthesis equation\nderive analysis equation\nspectrum plots\nstable LTI system response using DTFS\nproperties of DT FS\n\nCT Fourier Transform (OW §4.0 through 4.7)\n\nderive the CTFT pair from the CTFS\nDirichlet existence conditions\nCTFT of the CTFS\nProperties of the CT Fourier Transform\n\nlinearity\ntime shift\nconjugacy\nintegration and differentiation: application to LCCDE ↦\\mapsto CTFR\ntime scaling\nduality\nconvolution: stable LTI system response using CTFT\nmultiplication/modulation\napplication of the properties in combination\n\n\nDT Fourier Transform (OW §5.0 though 5.8)\n\nderive the DTFT from DTFS\nDTFT of DTFS\nProperties of the DT Fourier Transform\n\nperiodicity\nlinearity\nindex-shift: application to LCCDE ↦\\mapsto DTFR\nfrequency shift\nconjugation\nfinite difference and accumulation\ninterpolation /index expansion\nfrequency differentiation\nParseval’s\nconvolution: stable LTI system response using DTFT\nmultiplication/modulation\napplication of the properties in combination\n\n\nCT Frequency Response (OW §6.1, 6.2, 6.5)\n\nreview CTFR as CTFT of impulse response\nreview CTFR to/from LCCDE\nreview CTFR to/from block diagram\nmagnitude-phase representation of the frequency response\nfrequency response acting on sinusoids\nBode plots\n\nwhy plot it this way: dB units and log time axis\nhow to read them (not construct them manually)\nBode plots in software, e.g. Matlab/Python/Julia\n\nCTFR of first and second order systems\n\nDT Frequency Response (OW §6.1, 6.2, 6.6)\n\nreview DTFR as DTFT of impulse response\nreview DTFR to/from LCCDE\nreview DTFR to/from block diagram\nmagnitude-phase representation of the frequency response\nfrequency response acting on sinusoids\nDTFR plots\n\nperiodicity\ndB units\nDTFR plots in software, e.g. Matlab/Python/Julia\n\nDTFR of first and second order systems\n\nFrequency Selective Filters in CT (OW §3.9, 3.10, 6.3, 6.4)\n\nideal low-pass\nideal high-pass\nideal bandpass\nideal notch/bandstop\npractical filters\ntransformations\nfirst and second order systems as building blocks\n\nreview LCCDE representation\nreview block diagram representation\nreview CTFR representation\nCT 1st order RC+buffer\nCT Sallen-key\n\n\nFrequency Selective Filters in DT (OW §3.11, 6.3, 6.4)\n\nideal low-pass\nideal high-pass\nideal bandpass\nideal notch/bandstop\npractical filters\ntransformations\nfirst and second order systems as building blocks\n\nreview LCCDE representation\nreview block diagram representation\nreview DTFR representation\nDT 1st order implementation in code\nDT 2nd order implementation in code\n\n\nThe Discrete Fourier Transform\n\ntime window the DTFT to get the DFT\ninterpreting the index axis as DT and CT frequency\nzero-padding\noffline or batched filtering using the DFT\nbriefly mention fast algorithms to compute the DFT = FFT\n\nSampling (OW §7.1, 7.3, 7.4)\n\nsampling using the impulse train\nderive the Nyquist rate\neffects of aliasing\npractical ADC (sample and hold, SAR, bit-width)\ndesigning anti-aliasing filters\n\nReconstruction (OW §7.2)\n\nreconstruction as removal of images\nreconstruction as interpolation\npractical DAC: R-2R ladder\ndesigning reconstruction filters",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#graphical-outline",
    "href": "01-intro.html#graphical-outline",
    "title": "1  Course Introduction",
    "section": "1.4 Graphical Outline",
    "text": "1.4 Graphical Outline",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Introduction</span>"
    ]
  },
  {
    "objectID": "02-ct-signals.html",
    "href": "02-ct-signals.html",
    "title": "2  Continuous-Time Signals",
    "section": "",
    "text": "2.1 Signals as Functions\nA continuous-time (CT) signal is a function of one or more independent variables conveying information about a physical phenomena. This lecture gives an introduction to continuous-time signals as functions. You learn how to characterize such signals in a number of ways and are introduced to two very important signals: the unit impulse and the complex exponential.\nIn order to reason about signals mathematically we need a representation or model. Signals are modeled as functions, mappings between sets f:A→B\nf: A \\rightarrow B\n where AA is a set called the domain and BB is a set called the range.\nThe most basic classification of signals depends on the sets that makeup the domain and co-domain. We will be interested in two versions of the domain, the reals denoted ℝ\\mathbb{R} and the integers denoted ℤ\\mathbb{Z}. We will be interested in two versions of the co-domain, the reals ℝ\\mathbb{R} and the set of complex numbers ℂ\\mathbb{C}.\nSome other possibilities:\nThe co-domain can also be complex.\nSince the domains ℝ\\mathbb{R} and ℤ\\mathbb{Z} are usually interpreted as time, we will call these time-domain signals. In the time-domain, when the co-domain is ℝ\\mathbb{R} we call these real signals. All physical signals are real. However complex signals will become important when we discuss the frequency domain.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Continuous-Time Signals</span>"
    ]
  },
  {
    "objectID": "02-ct-signals.html#signals-as-functions",
    "href": "02-ct-signals.html#signals-as-functions",
    "title": "2  Continuous-Time Signals",
    "section": "",
    "text": "Example\n\n\nAnalog Signal: If the function f:ℝ→ℝf: \\mathbb{R} \\rightarrow \\mathbb{R}, we call this an analog or real, continuous-time signal, e.g. a voltage at time t∈ℝt \\in \\mathbb{R}, v(t)v(t). We will write these as x(t)x(t), y(t)y(t), etc. The units of tt are seconds. Figure 2.1 shows some graphical representations, i.e. plots.\n\n\nCode\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nt = np.linspace(-6, 6, 1000);\nu = (t &gt;= 0)\ne = np.exp(-t)*u\ns = np.sin(2*np.pi*t)\nes = e*s\n\nf = plt.figure()\n\nplt.subplot(2, 2, 1)\nplt.plot(np.linspace(-6, 0, 1000), np.zeros(1000), color='b')\nplt.plot(np.linspace(0, 6, 1000), np.ones(1000), color='b')\nplt.xlabel('$t$')\nplt.ylabel('$x(t)$')\nplt.title('$x(t) = u(t)$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.subplot(2, 2, 2)\nplt.plot(t,e)\nplt.xlabel('$t$')\nplt.ylabel('$x(t)$')\nplt.title('$x(t) = e^{-t}u(t)$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.subplot(2, 2, 3)\nplt.plot(t,s)\nplt.xlabel('$t$')\nplt.ylabel('$x(t)$')\nplt.title('$x(t) = sin(2\\pi t)$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.subplot(2, 2, 4)\nplt.plot(t,es)\nplt.xlabel('$t$')\nplt.ylabel('$x(t)$')\nplt.title('$x(t) = e^{-t}sin(2\\pi t)u(t)$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.tight_layout()\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2.1: Example plots of analog signals.\n\n\n\n\n\n\n\n\n\nExample\n\n\nReal, Discrete-time Signal: If the function f:ℤ→ℝf: \\mathbb{Z} \\rightarrow \\mathbb{R}, we call this a real, discrete-time signal, e.g. the temperature every day at noon. We will write these as x[n]x[n], y[n]y[n], etc. Note nn is dimensionless. Figure 2.2 shows some graphical representations.\n\n\nCode\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nn = np.linspace(-6, 6, 13);\nu = (n &gt;= 0)\ne = np.exp(-n)*u\ns = np.sin(n)\nes = e*s\n\nf = plt.figure()\n\nplt.subplot(2, 2, 1)\nplt.stem(n, u)\nplt.xlabel('$n$')\nplt.ylabel('$x[n]$')\nplt.title('$x[n] = u[n]$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.subplot(2, 2, 2)\nplt.stem(n,e)\nplt.xlabel('$n$')\nplt.ylabel('$x[n]$')\nplt.title('$x[n] = e^{-n}u[n]$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.subplot(2, 2, 3)\nplt.stem(n,s)\nplt.xlabel('$n$')\nplt.ylabel('$x[n]$')\nplt.title('$x[n] = sin(n)$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.subplot(2, 2, 4)\nplt.stem(n,es)\nplt.xlabel('$n$')\nplt.ylabel('$x[n]$')\nplt.title('$x[n] = e^{-n}sin(n)u[n]$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2.2: Example plots of real-valued, discrete-time signals.\n\n\n\n\n\n\n\n\n\nf:ℝ→ℤf: \\mathbb{R} \\rightarrow \\mathbb{Z}, digital, continuous-time signals, e.g. the output of a general purpose pin on a microcontroller\nf:ℤ→ℤf: \\mathbb{Z} \\rightarrow \\mathbb{Z}, digital, discrete-time signals, e.g. the signal on a computer bus\n\n\n\nf:ℝ→ℂf: \\mathbb{R} \\rightarrow \\mathbb{C}, complex-valued, continuous-time signals, e.g. x(t)=ejωt=cos(ωt)+jsin(ωt)\nx(t) = e^{j\\omega t} = \\cos(\\omega t) + j\\sin(\\omega t)\n\nf:ℤ→ℂf: \\mathbb{Z} \\rightarrow \\mathbb{C}, complex-valued, discrete-time signals, e.g. x[n]=ejωn=cos(ωn)+jsin(ωn)\nx[n] = e^{j\\omega n} = \\cos(\\omega n) + j\\sin(\\omega n)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Continuous-Time Signals</span>"
    ]
  },
  {
    "objectID": "02-ct-signals.html#primitive-models",
    "href": "02-ct-signals.html#primitive-models",
    "title": "2  Continuous-Time Signals",
    "section": "2.2 Primitive Models",
    "text": "2.2 Primitive Models\nWe mathematically model signals by combining elementary/primitive functions, for example:\n\npolynomials: x(t)=tx(t) = t, x(t)=t2x(t) = t^2, etc.\ntransendental functions: x(t)=etx(t) = e^t, x(t)=sin(t)x(t) = \\sin(t), x(t)=cos(t)x(t) = \\cos(t), etc.\npiecewise functions, e.g. x(t)={f1(t)t&lt;0f2(t)t≥0\n   x(t) = \\left\\{  \\begin{array}{cl}\n     f_1(t) & t &lt; 0\\\\\n     f_2(t) & t \\geq 0\\\\\n   \\end{array}\\right.\n\n\n\n\nExample\n\n\nModeling a Switch: Consider a mathematical model of a switch, which moves positions at time t=0t = 0.\n\n\n\n\n\nWe use this model so much we give it it’s own name and symbol: Unit Step, u(t)u(t)\nu(t)={0t&lt;01t≥0\nu(t) = \\left\\{  \\begin{array}{cl}\n        0 & t &lt; 0\\\\\n        1 & t \\geq 0\\\\\n      \\end{array}\\right.\n so a mathematical model of the switch circuit above would be x(t)=Vu(t)x(t) = V u(t).\nNote: some texts define the step function at t=0t=0 to be 11 or 12\\frac{1}{2}. It is typically plotted like so:\n\n\n\n\n\n\n\n\n\nExample\n\n\nPure audio tone at “middle C”. A signal modeling the air pressure of a specific tone might be\nx(t)=sin(2π(261.6)t)\n  x(t) = \\sin\\left(2\\pi (261.6) t\\right)\n\n\n\n\n\nExample\n\n\nChord. The chord “G”, an additive mixture of tones at G, B, and D and might be modeled as\nx(t)=sin(2π(392)t)+sin(2π(494)t)+sin(2π(293)t)\nx(t) = \\sin\\left(2\\pi (392) t\\right) + \\sin\\left(2\\pi (494) t\\right) + \\sin\\left(2\\pi (293) t\\right) \n\nThis example shows we can use addition to build-up signals to approximate real signals of interest.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Continuous-Time Signals</span>"
    ]
  },
  {
    "objectID": "02-ct-signals.html#basic-transformations",
    "href": "02-ct-signals.html#basic-transformations",
    "title": "2  Continuous-Time Signals",
    "section": "2.3 Basic Transformations",
    "text": "2.3 Basic Transformations\nWe can also apply transformations to signals to increase their modeling flexibility.\n\nmagnitude scaling x2(t)=ax1(t)\nx_2(t) = a x_1(t)\n for a∈ℝa \\in \\mathbb{R}.\nderivatives x2(t)=x1′(t)=dx1dt(t)\nx_2(t) = x_1^\\prime(t) = \\frac{d x_1}{dt}(t)\n\nintegrals x2(t)=∫−∞tx1(τ)dτ\nx_2(t) = \\int\\limits_{-\\infty}^t x_1(\\tau) \\; d\\tau\n\nsums y(t)=∑ixi(t)\ny(t) = \\sum\\limits_{i} x_i(t)\n an important example we will see is the CT Fourier series.\n\nmultiplication (modulation) y(t)=x1(t)x2(t)\ny(t) = x_1(t) x_2(t)\n For example amplitude modulation y(t)=x(t)sin(ω0t)y(t) = x(t)\\sin(\\omega_0 t)\ntime shift x2(t)=x1(t+τ)\nx_2(t) = x_1(t+\\tau)\n\n\nif τ&lt;0\\tau &lt;0 it is called a delay\nif τ&gt;0\\tau &gt;0 it is called an advance\n\ntime scaling x2(t)=x1(tτ)\n  x_2(t) = x_1\\left(\\frac{t}{\\tau}\\right)\n  \n\nif τ&gt;1\\tau &gt;1 increasing τ\\tau expands in time, slows down the signal\nif 0&lt;τ&lt;10 &lt; \\tau &lt; 1 decreasing τ\\tau contracts in time, speeds up the signal\nif −1&lt;τ&lt;0-1 &lt; \\tau &lt;0 time reverses and increasing τ\\tau contracts in time, speeding up the signal\nif τ&lt;−1\\tau &lt; -1 time reverses and decreasing τ\\tau expands in time, slows down the signal\n\nCommon uses are time reversal, x2(t)=x1(−t)x_2(t) = x_1(-t), and changing the frequency of of sinusoids.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Continuous-Time Signals</span>"
    ]
  },
  {
    "objectID": "02-ct-signals.html#characterization-of-signals",
    "href": "02-ct-signals.html#characterization-of-signals",
    "title": "2  Continuous-Time Signals",
    "section": "2.4 Characterization of Signals",
    "text": "2.4 Characterization of Signals\nThere are a few basic ways of characterizing signals.\n\n\nDefinition\n\n\nCausal CT Signal. A CT signal is if x(t)=0x(t) = 0 ∀t&lt;0\\forall t &lt; 0.\nAnti-Causal CT Signal. A CT signal is or acausal if x(t)=0x(t) = 0 ∀t≥0\\forall t \\geq 0.\n\n\nA signal can be written as the sum of a causal and anti-causal signal.\n\n\nDefinition\n\n\nPeriodic Signals. A CT signal is if x(t)=x(t+T)x(t) = x(t + T) ∀t\\forall t for a fixed parameter T∈ℝT \\in \\mathbb{R} called the .\n\n\nThe simplest periodic signals are those based on the sinusoidal functions.\n\n\nDefinition\n\n\nEven Signal. A CT signal is if x(t)=x(−t)x(t) = x(-t) ∀t\\forall t.\nOdd Signal.  A CT signal is if x(t)=−x(−t)x(t) = -x(-t) ∀t\\forall t.\n\n\nAny CT signal can be written in terms of an even and odd component x(t)=xe(t)+xo(t)\nx(t) = x_e(t) + x_o(t) \n where xe(t)=12{x(t)+x(−t)}xo(t)=12{x(t)−x(−t)}\n\\begin{array}{ll}\n  x_e(t) &= \\frac{1}{2}\\left\\{x(t) + x(-t)\\right\\} \\\\\n  & \\\\\n  x_o(t) &= \\frac{1}{2}\\left\\{x(t) - x(-t)\\right\\}\n\\end{array}\n\n\n\nDefinition\n\n\nEnergy of a CT Signal. The energy of a CT signal x(t)x(t) is defined as a measure of the function Ex=limT→∞∫−TT|x(t)|2dt.\n  E_x = \\lim_{T\\rightarrow\\infty} \\int\\limits_{-T}^T \\lvert x(t) \\rvert^2 dt \\; .\n  \n\n\n\n\nDefinition\n\n\nPower of a CT Signal. The power of a CT signal is the energy averaged over an interval as that interval tends to infinity. Px=limT→∞12T∫−TT|x(t)|2dt.\n  P_x = \\lim_{T\\rightarrow\\infty} \\frac{1}{2T} \\int_{-T}^T \\lvert x(t)\\rvert^2 dt \\; .\n  \n\n\nSignals can be characterized based on their energy or power:\n\nSignals with finite, non-zero energy and zero power are called energy signals.\nSignals with finite, non-zero power (and by implication infinite energy) are called power signals.\n\nNote, these categories are non-exclusive, some signals are neither energy or power signals.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Continuous-Time Signals</span>"
    ]
  },
  {
    "objectID": "02-ct-signals.html#unit-impulse-function",
    "href": "02-ct-signals.html#unit-impulse-function",
    "title": "2  Continuous-Time Signals",
    "section": "2.5 Unit Impulse Function",
    "text": "2.5 Unit Impulse Function\nAn important CT signal is the unit impulse function, also called the “delta” δ\\delta function for the symbol traditionally used to define it. Applying this signal to a system models a “kick” to that system. For example, consider striking a tuning fork. The reason this signal is so important is that it will turn out that the response of the system to this input tells us all we need to know about a linear, time-invariant system!\n\n\nExample\n\n\nCT Impulse Function. The CT impulse function is not really a function at all, but a mathematical object called a “distribution”. Some equivalent definitions:\nδ(t)=limϵ→0{12ϵ|t|&lt;ϵ0else\n\\delta(t) = \\lim_{\\epsilon \\rightarrow 0}\\left\\{\n\\begin{array}{ll}\n  \\frac{1}{2\\epsilon} & |t| &lt; \\epsilon\\\\\n  0 & \\text{else}\n\\end{array}\n\\right.\n\nδ(t)=limϵ→012πϵe−t22ϵ2\n\\delta(t) = \\lim_{\\epsilon \\rightarrow 0} \\frac{1}{\\sqrt{2\\pi}\\epsilon} e^{-\\frac{t^2}{2\\epsilon^2}}\n Note the area under each definition is always one.\n\n\nIn practice we can often use the following definition and some properties, without worrying about the distribution functions. δ(t)={0t≠0∞t=0\n\\delta(t) = \\left\\{\n\\begin{array}{ll}\n  0 & t \\neq 0\\\\\n  \\infty & t = 0\n\\end{array}\n\\right. \n which we draw as a vertical arrow in plots:\n\n\n\nThe delta function shown as a graph.\n\n\nNote the height of the arrow is arbitrary. Often in the case of a non-unit impulse function the area is written in parenthesis near the arrow tip.\nThe following properties of the impulse function will be used often.\n\nThe area under the unit impulse is unity since by definition ∫−∞∞δ(t)dt=1\n\\int\\limits_{-\\infty}^{\\infty} \\delta(t) \\; dt = 1\n\nSampling property: x(t)δ(t−t0)=x(t0)δ(t−t0)x(t)\\delta(t-t_0) = x(t_0)\\delta(t-t_0)\nSifting Property: ∫abx(t)δ(t−t0)dt=x(t0)\n\\int\\limits_{a}^{b} x(t)\\delta(t-t_0) \\; dt = x(t_0)\n for any a&lt;t0&lt;ba &lt; t_0 &lt; b.\n\nWe previously defined the unit step function. The impulse can be defined in terms of the step: δ(t)=dudt\n\\delta(t) = \\frac{du}{dt}\n and vice-versa u(t)=∫−∞tδ(τ)dτ\nu(t) = \\int\\limits_{-\\infty}^{t} \\delta(\\tau) \\; d\\tau\n using the notion of distributions, e.g.\nu(t)=∫−∞tδ(τ)dτ=limϵ→0∫−∞t12πϵe−τ22ϵ2dτ=limϵ→012(1+erf(t2ϵ))\nu(t) = \\int\\limits_{-\\infty}^{t} \\delta(\\tau) \\; d\\tau = \\lim_{\\epsilon \\rightarrow 0} \\int\\limits_{-\\infty}^{t} \\frac{1}{\\sqrt{2\\pi}\\epsilon} e^{-\\frac{\\tau^2}{2\\epsilon^2}} \\; d\\tau = \\lim_{\\epsilon \\rightarrow 0} \\frac{1}{2}\\left(1+\\text{erf}\\left( \\frac{t}{\\sqrt{2}\\epsilon}\\right)\\right)\n\nThe step and impulse function are related, but in many cases finding the response of a system to a step input is easier.\nWe can apply additional transformations to the impulse and step functions to get other useful signals, e.g.\n\nramp r(t)=∫−∞tu(τ)dτ=tu(t)\nr(t) = \\int\\limits_{-\\infty}^{t} u(\\tau) \\; d\\tau = tu(t)\n\ncausal pulse of width ϵ\\epsilon p(t)=u(t)−u(t−ϵ)\np(t) = u(t) - u(t-\\epsilon)\n\nnon-causal pulse of width 2ϵ2\\epsilon p(t)=u(t+ϵ)−u(t−ϵ)\n    p(t) = u(t+\\epsilon) - u(t-\\epsilon)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Continuous-Time Signals</span>"
    ]
  },
  {
    "objectID": "02-ct-signals.html#ct-complex-exponential",
    "href": "02-ct-signals.html#ct-complex-exponential",
    "title": "2  Continuous-Time Signals",
    "section": "2.6 CT Complex Exponential",
    "text": "2.6 CT Complex Exponential\nOne of the most important signals in systems theory is the complex exponential: x(t)=Ceat\nx(t) = C\\, e^{a t}\n where the parameters C,a∈ℂC, a \\in \\mathbb{C} in general.\nWhen CC and aa are both real (ℑ(C)=ℑ(a)=0\\Im(C) = \\Im(a) = 0), we have the familiar exponential. When a&gt;0a &gt; 0 and C&gt;0C &gt; 0, x(t)=Ceatx(t) = C e^{a t} looks like:\n\n\n\n\n\nWhen a&lt;0a &lt; 0 and C&gt;0C &gt; 0, x(t)=Ceatx(t) = C e^{a t} looks like:\n\n\n\n\n\nIf C&lt;0C &lt; 0 the signals reflect about the time axis.\nTo get the pure sinusoidal case, let C∈ℝC \\in \\mathbb{R} and aa be purely imaginary: a=jω0a = j\\omega_0: x(t)=Cejω0t\nx(t) = Ce^{j\\omega_0 t}\n where ω0\\omega_0 is the frequency (in radians/sec). This is called the complex sinusoid.\nBy Euler’s identity: ejω0t=cos(ω0t)+jsin(ω0t)\ne^{j\\omega_0 t} = \\cos(\\omega_0 t) + j\\sin(\\omega_0 t)\n and ℜ(x(t))=cos(ω0t)=12(ejω0t+e−jω0t)\n\\Re(x(t)) = \\cos(\\omega_0 t) = \\frac{1}{2}\\left( e^{j\\omega_0 t} + e^{-j\\omega_0 t} \\right)\n\nℑ(x(t))=sin(ω0t)=12j(ejω0t−e−jω0t)\n\\Im(x(t)) = \\sin(\\omega_0 t) = \\frac{1}{2j}\\left( e^{j\\omega_0 t} - e^{-j\\omega_0 t} \\right)\n are both real sinusoids.\nNote that the sinusoids are periodic. Recall a signal x(t)x(t) is periodic with period TT if x(t)=x(t+T)∀t\nx(t) = x(t+T) \\; \\forall t\n In the case of the complex sinusoid Cejω0t=Cejω0(t+T)=Cejω0tejω0T⏟must be 1\nCe^{j\\omega_0 t} = Ce^{j\\omega_0 (t+T)}= Ce^{j\\omega_0 t}\\underbrace{e^{j\\omega_0 T}}_{\\text{must be 1}}\n\n\nif ω0=0\\omega_0 = 0 this is true for all TT\nif ω0≠0\\omega_0 \\neq 0, then to be periodic ω0T=2πm\\omega_0 T = 2\\pi m for m=±1,±2,⋯m = \\pm 1, \\pm 2, \\cdots. The smallest TT for which this is true is the fundamental period T0T_0 T0=2π|ω0|\nT_0 = \\frac{2\\pi}{|\\omega_0|}\n or equivalently ω0=2πT0\\omega_0 = \\frac{2\\pi}{T_0}\n\nSome useful properties of sinusoids:\n\nIf x(t)x(t) is periodic with period TT and gg is any function then g(x(t))g(x(t)) is periodic with period TT.\nIf x1(t)x_1(t) is periodic with period T1T_1 and x2(t)x_2(t) is periodic with period T2T_2, and if there exists positive integers a,ba,b such that aT1=bT2=P\naT_1 = b T_2 = P\n then x1(t)+x2(t)x_1(t) + x_2(t) and x1(t)x2(t)x_1(t)x_2(t) are periodic with period PP\n\nThe last property implies that both T1T_1 and T2T_2 must both be rational in π\\pi or neither should be. For example\n\nx(t)=sin(2πt)+cos(5πt)x(t) = \\sin(2\\pi t) + \\cos(5\\pi t) is periodic\nx(t)=sin(2t)+cos(5t)x(t) = \\sin(2 t) + \\cos(5 t) is periodic\nx(t)=sin(2πt)+cos(5t)x(t) = \\sin(2\\pi t) + \\cos(5 t) is not periodic\n\nWhen the parameter CC is complex we get a phase shift. Again let a=jω0a = j\\omega_0. When CC is complex we can write it as C=AejϕC = Ae^{j\\phi} where A=|C|A = |C| and ϕ=∠C\\phi = \\angle C. Then\nx(t)=Aejϕejω0t=Aej(ω0t+ϕ)\nx(t) = Ae^{j\\phi} e^{j\\omega_0 t} = Ae^{j(\\omega_0 t+\\phi)} \n and ℜ(x(t))=Acos(ω0t+ϕ)\n\\Re(x(t)) = A\\cos(\\omega_0 t+\\phi) \n\nℑ(x(t))=Asin(ω0t+ϕ)\n\\Im(x(t)) = A\\sin(\\omega_0 t+\\phi) \n\nSince sin\\sin is a special case of cos\\cos, i.e. cos(θ)=sin(θ+π2)\\cos(\\theta) = \\sin(\\theta + \\frac{\\pi}{2}), the general real sinusoid is\nAcos(ω0t+ϕ)\nA\\cos(\\omega_0 t + \\phi)\n\n\nAA is called the amplitude\nω0\\omega_0 is again the frequency in radians/sec.\nϕ\\phi is called the phase shift and is related to a time shift TsT_s by ϕ=ω0Ts\n\\phi = \\omega_0T_s\n\n\nFor example the signal graphically represented as follows\n\n\nCode\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nmatplotlib.rcParams.update({'font.size': 12})\n\nt = np.linspace(-2*np.pi, 2*np.pi, 1000);\nx = 2*np.cos(np.pi*t -np.pi/4);\n\nf = plt.figure()\n\nplt.plot(t, x)\nplt.xlabel('$t$')\nplt.autoscale(enable=True, axis='x', tight=True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2.3: Example plot of sinusoidal signal.\n\n\n\n\n\nhas the functional representation\nx(t)=2cos(π2(t+12))=2cos(π2t+π4)\nx(t) = 2\\cos\\left(\\frac{\\pi}{2} (t+\\tfrac{1}{2}) \\right) =  2\\cos\\left(\\frac{\\pi}{2} t +\\frac{\\pi}{4} \\right)\n\n\n2.6.1 Energy of CT complex sinusoid\nRecall the energy of a CT signal x(t)x(t) is\nEx=limT→∞∫−TT|x(t)|2dt.\n  E_x = \\lim_{T\\rightarrow\\infty} \\int\\limits_{-T}^T \\lvert x(t) \\rvert^2 dt \\; .\n Substituting x(t)=ejω0tx(t) = e^{j\\omega_0 t} and letting T=NT0T = N T_0 Ex=limN→∞∫−NT0NT0|ejω0t|2⏟always 1dt=limN→∞2NT0=∞\n    E_x = \\lim_{N\\rightarrow\\infty} \\int\\limits_{-N T_0}^{N T_0} \\underbrace{\\lvert e^{j\\omega_0 t} \\rvert^2}_{\\text{always 1}} \\; dt = \\lim_{N\\rightarrow\\infty} 2NT_0 = \\infty\n\n\n\n2.6.2 Power of CT complex sinusoid\nRecall the power of a CT signal x(t)x(t) is Px=limT→∞12T∫−TT|x(t)|2dt.\n  P_x = \\lim_{T\\rightarrow\\infty} \\frac{1}{2T} \\int\\limits_{-T}^T \\lvert x(t) \\rvert^2 dt \\; .\n Again, substituting x(t)=ejω0tx(t) = e^{j\\omega_0 t} and letting T=NT0T = N T_0 Px=limN→∞12NT0∫−NT0NT0|ejω0t|2⏟always 1dt=limN→∞12NT02NT0=1\n  P_x = \\lim_{N\\rightarrow\\infty} \\frac{1}{2NT_0} \\int\\limits_{-N T_0}^{N T_0} \\underbrace{\\lvert e^{j\\omega_0 t} \\rvert^2}_{\\text{always 1}} \\; dt = \\lim_{N\\rightarrow\\infty} \\frac{1}{2NT_0} 2NT_0 = 1\n\n\n\n2.6.3 Harmonics\nTwo CT complex sinusoids are harmonics of one another is both are periodic in T0T_0. This occurs when\nxk(t)=ejkω0tfork=0,±1,±2,⋯\n    x_k(t) = e^{jk\\omega_0 t} \\; \\text{for} \\; k = 0, \\pm 1, \\pm 2, \\cdots\n\nThe term comes from music where the vibrations of a string instrument are modeled as a weighted combination of harmonic tones.\n\n\n2.6.4 Geometric interpretation of the Complex Exponential\nIn the general case we get a sinusoid signal modulated by an exponential. Let C=AejϕC = Ae^{j\\phi} and a=r+jω0a = r + j\\omega_0, then x(t)=Ceat=Aejϕe(r+jω0)t\n  x(t) = C e^{a t} =  Ae^{j\\phi} e^{(r+j\\omega_0)t}\n Expanding the terms and using Euler’s identity gives: x(t)=Aertcos(ω0t+ϕ)⏟ℜpart+jAertsin(ω0t+ϕ)⏟ℑpart\nx(t) = \\underbrace{Ae^{rt}\\cos(\\omega_0 t+\\phi)}_{\\Re \\text{part}} + j \\underbrace{Ae^{rt}\\sin(\\omega_0 t+\\phi)}_{\\Im \\text{part}}\n Each part is a real sinusoid whose amplitude is modulated by a real exponential.\nAn important visualization of the general case is to view the signal x(t)x(t) as a vector rotating counter-clockwise in the complex plane for positive tt.\n\n\n\nThe CT complex sinusoid at a specific point in time.\n\n\nFor r&lt;0r &lt; 0 the tip of the arrow traces out an inward spiral, whereas for r&gt;0r &gt; 0 it traces out an outward spiral. For r=0r = 0 it traces out the unit circle.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Continuous-Time Signals</span>"
    ]
  },
  {
    "objectID": "02-ct-signals.html#example-problems",
    "href": "02-ct-signals.html#example-problems",
    "title": "2  Continuous-Time Signals",
    "section": "2.7 Example Problems",
    "text": "2.7 Example Problems\n\n2.7.1 \nConsider a signal described by the function x(t)=e−3tsin(10πt)u(t)\n  x(t) = e^{-3t}\\sin(10\\pi t)u(t)\n   \n\nDetermine the magnitude and phase of x(120)x\\left( \\frac{1}{20}\\right)\n\nSolution:\nSubstituting t=120t = \\frac{1}{20} gives x(120)=e−3120sin(10π120)u(120)=e−320≈0.86\n  x\\left( \\frac{1}{20}\\right) = e^{-3\\frac{1}{20}}\\sin\\left(10\\pi \\frac{1}{20}\\right)u\\left( \\frac{1}{20}\\right) = e^{-\\frac{3}{20}} \\approx 0.86\n   Since the signal is purely real and exponential is always positive, the magnitude is |x(120)|=|e−320|=e−320≈0.86\n  \\left|x\\left( \\frac{1}{20}\\right)\\right| = \\left| e^{-\\frac{3}{20}}\\right| =  e^{-\\frac{3}{20}}  \\approx 0.86\n   and the phase is ∠x(120)=0\n  \\angle x\\left( \\frac{1}{20}\\right) = 0\n  \n\nUsing Matlab, plot the signal |x(t)||x(t)| between [−2,2][-2, 2]. Give your code and embed the plot.\n\nSolution:\n% Solution to Example Problem 2.7.1b\n1t = -2:0.001:2;\n2x = exp(-3*t).*sin(10*pi*t).*heaviside(t);\n3hp = plot(t,abs(x));\ngrid on;\nxh = xlabel('t');\nyh = ylabel('x(t)');\nth = title('Plot for Example Problem 2.7.1b');\n\n% make the plot more readable\nset(gca, 'FontSize', 12, 'Box', 'off', 'LineWidth', 2);\nset(hp, 'linewidth', 2);\nset([xh, yh, th], 'FontSize', 12);\n\nset(gcf, 'PaperPositionMode', 'auto');\nprint -dpng example_2_7_1.png\n\n1\n\nCreate time slices from -2 seconds to 2 seconds in increments of 1 millisecond\n\n2\n\nCompute the signal value at each time slice\n\n3\n\nPlot the signal\n\n\n\n\n2.7.2 \nFind a solution to the differential equation dydt(t)+9y(t)=e−t\n  \\frac{dy}{dt}(t) + 9y(t) = e^{-t}\n   for t≥0t \\geq 0, when y(0)=1y(0) = 1.\nSolution: The homogeneous equation is dyhdt(t)+9yh(t)=0\n  \\frac{dy_h}{dt}(t) + 9y_h(t) = 0\n   with initial condition yh(0)=1y_h(0) = 1. Its solution is of the form yh(t)=Ce−9t\n  y_h(t) = C\\, e^{-9t} \n   for constant CC. Using the initial condition yh(0)=Ce−0=C=1\n  y_h(0) = C\\, e^{-0} = C = 1\n   gives yh(t)=e−9t\n  y_h(t) = e^{-9t} \n   The particular solution is of the form yp(t)=C1e−t+C2e−9t\n  y_p(t) = C_1 e^{-t} + C_2 e^{-9t}\n   Substitution and equating coefficients gives C1=18C_1 = \\frac{1}{8} and C2=−18C_2 = -\\frac{1}{8}. The total solution is the sum of the two solutions or y(t)=18e−t−18e−9t+e−9t=18e−t+78e−9t\n  y(t) = \\frac{1}{8} e^{-t} - \\frac{1}{8} e^{-9t} + e^{-9t} = \\frac{1}{8} e^{-t} + \\frac{7}{8} e^{-9t}\n  \n\n\n2.7.3 \nFind a solution to the differential equation dydt(t)+9y(t)=e−t\n  \\frac{dy}{dt}(t) + 9y(t) = e^{-t}\n   for t≥0t \\geq 0, when y(0)=1y(0) = 1.\nSolution: The homogeneous equation is dyhdt(t)+9yh(t)=0\n  \\frac{dy_h}{dt}(t) + 9y_h(t) = 0\n   with initial condition yh(0)=1y_h(0) = 1. Its solution is of the form yh(t)=Ce−9t\n  y_h(t) = C\\, e^{-9t} \n   for constant CC. Using the initial condition yh(0)=Ce−0=C=1\n  y_h(0) = C\\, e^{-0} = C = 1\n   gives yh(t)=e−9t\n  y_h(t) = e^{-9t} \n   The particular solution is of the form yp(t)=C1e−t+C2e−9t\n  y_p(t) = C_1 e^{-t} + C_2 e^{-9t}\n   Substitution and equating coefficients gives C1=18C_1 = \\frac{1}{8} and C2=−18C_2 = -\\frac{1}{8}. The total solution is the sum of the two solutions or y(t)=18e−t−18e−9t+e−9t=18e−t+78e−9t\n  y(t) = \\frac{1}{8} e^{-t} - \\frac{1}{8} e^{-9t} + e^{-9t} = \\frac{1}{8} e^{-t} + \\frac{7}{8} e^{-9t}\n  \n\n\n2.7.4 \nCompute the integral ∫−∞∞e−t2δ(t−10)dt\n    \\int\\limits_{-\\infty}^{\\infty} e^{-t^2} \\, \\delta(t-10)\\; dt\n     where δ(t)\\delta(t) is the delta function.\nSolution:\nUsing the sifting property of the delta function ∫abf(t)δ(t−t0)dt=f(t0)\n  \\int\\limits_{a}^{b} f(t) \\, \\delta(t-t_0)\\; dt = f(t_0)\n   for a&lt;t0&lt;ba &lt; t_0 &lt; b, we get ∫−∞∞e−t2δ(t−10)dt=e−100≈0\n  \\int\\limits_{-\\infty}^{\\infty} e^{-t^2} \\, \\delta(t-10)\\; dt = e^{-100} \\approx 0",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Continuous-Time Signals</span>"
    ]
  },
  {
    "objectID": "03-dt-signals.html",
    "href": "03-dt-signals.html",
    "title": "3  Discrete-Time Signals",
    "section": "",
    "text": "3.1 Primitive Models\nRecall from the previous chapter that a discrete-time (DT) signal is modeled as a function f:ℤ→ℂf: \\mathbb{Z} \\rightarrow \\mathbb{C}. We will write these as x[n]x[n], y[n]y[n], etc. Note nn is dimensionless. These are graphically plotted as stem or “lollipop” plots, as demonstrated in Chapter 2.\nSince the domain ℤ\\mathbb{Z} is usually interpreted as a time index, we will still call these {} signals. In the time-domain, when the co-domain is ℝ\\mathbb{R} we call these real DT signals. Unlike with CT signals there are no physical limitations requiring DT signals to be real, since in discrete hardware, a value at a given index can be a complex number, i.e. just a pair of numbers. However it is computationally advantageous to restrict ourselves to real arithmetic and such signals are often converted to or from CT signals, which do have to be real. For this reason, real DT signals dominate in models.\nAs with CT signals, we mathematically model DT signals by combining elementary/primitive functions, for example:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Discrete-Time Signals</span>"
    ]
  },
  {
    "objectID": "03-dt-signals.html#primitive-models",
    "href": "03-dt-signals.html#primitive-models",
    "title": "3  Discrete-Time Signals",
    "section": "",
    "text": "polynomials: x[n]=nx[n] = n, x[n]=n2x[n] = n^2, etc.\ntransendental functions: x[n]=enx[n] = e^n, x[n]=sin(n)x[n] = \\sin(n), x[n]=cos(n)x[n] = \\cos(n), etc.\npiecewise functions, e.g. x[n]={f1[n]n&lt;0f2[n]n≥0\nx[n] = \\left\\{  \\begin{array}{cl}\nf_1[n] & n &lt; 0\\\\\nf_2[n] & n \\geq 0\\\\\n\\end{array}\\right.\n\n\n\n\nDefinition\n\n\nThe DT counterpart of the CT step function is the DT Unit Step, u[n]u[n]: u[n]={0n&lt;01n≥0u[n] = \\left\\{  \\begin{array}{cl}\n    0 & n &lt; 0\\\\\n    1 & n \\geq 0\\\\\n  \\end{array}\\right. Note, there are not continuity issues at n=0n=0 as DT functions have discrete domains.\n\n\n\n\nExample\n\n\nA sampled signal modeling the air pressure of a specific tone, sampled at 8kHz, might be x[n]=sin(2π(261.6)18000n)x[n] = \\sin\\left(2\\pi (261.6) \\tfrac{1}{8000} n\\right) Such DT signals are commonly used in digital music generation, storage, and playback.\n\n\n\n\nExample\n\n\nSimilarly, the sampled chord \"G\", an additive mixture of tones at G, B, and D and might be modeled as x[n]=sin(2π(392)18000n)+sin(2π(494)18000n)+sin(2π(293)18000n)x[n] = \\sin\\left(2\\pi (392) \\tfrac{1}{8000} n\\right) + \\sin\\left(2\\pi (494) \\tfrac{1}{8000} n\\right) + \\sin\\left(2\\pi (293) \\tfrac{1}{8000} n\\right) again sampled at 8kHz. This example shows we can use addition to build-up signals to approximate real signals of interest.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Discrete-Time Signals</span>"
    ]
  },
  {
    "objectID": "03-dt-signals.html#basic-transformations",
    "href": "03-dt-signals.html#basic-transformations",
    "title": "3  Discrete-Time Signals",
    "section": "3.2 Basic Transformations",
    "text": "3.2 Basic Transformations\nSimilar to CT signals, we can also apply transformations to DT signals to increase their modeling flexibility.\n\nmagnitude scaling x2[n]=ax1[n]x_2[n] = a x_1[n] for a∈ℝa \\in \\mathbb{R}.\ntime differences x2[n]=x1[n]−x1[n−1]x_2[n] = x_1[n] - x_1[n-1]\nrunning sums x2[n]=∑m=−∞nx1[m]x_2[n] = \\sum\\limits_{m = -\\infty}^{n} x_1[m]\nsums y[n]=∑ixi[n]y[n] = \\sum\\limits_{i} x_i[n] an important example we will see is the DT Fourier series.\nmultiplication (modulation) y[n]=x1[n]x2[n]y[n] = x_1[n] x_2[n]\ntime index shift x2[n]=x1[n+m]x_2[n] = x_1[n+m]\n\nif m&lt;0m &lt; 0 it is called a delay\nif m&gt;0m &gt; 0 it is called an advance\n\ntime reversal x2[n]=x1[−n]x_2[n] = x_1[-n]\ndecimation y[n]=x[mn]y[n] = x[m n] for m∈ℤ+m \\in \\mathbb{Z}^+.\n\ne.g. for m=2m=2 only keep every other sample\ne.g. for m=3m=3 only keep every third sample\netc.\n\ninterpolation y[n]={x[nm]n=0,±m,,±2m⋯0elsey[n] = \\left\\{  \\begin{array}{cl}\nx\\left[ \\frac{n}{m}\\right] & n = 0\\; , \\; \\pm m, , \\; \\pm 2m \\cdots\\\\\n0 & \\mbox{else}\n\\end{array}\\right. When m=2m = 2 this inserts a zero sample between every sample of the signal.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Discrete-Time Signals</span>"
    ]
  },
  {
    "objectID": "03-dt-signals.html#characterization-of-signals",
    "href": "03-dt-signals.html#characterization-of-signals",
    "title": "3  Discrete-Time Signals",
    "section": "3.3 Characterization of Signals",
    "text": "3.3 Characterization of Signals\nThere are a few basic ways of characterizing DT signals.\n\n\nDefinition\n\n\nA DT signal is causal if x[n]=0x[n] = 0 ∀n&lt;0\\forall n &lt; 0.\n\n\n\n\nDefinition\n\n\nA DT signal is anti-causal or acausal if x[n]=0x[n] = 0 ∀n≥0\\forall n \\geq 0.\n\n\nA DT signal can be written as the sum of a causal and anti-causal signal.\nA DT signal is periodic if x[n]=x[n+N]∀nx[n] = x[n + N] \\; \\forall n for a fixed period N∈ℤN \\in \\mathbb{Z}.\nA DT signal is even if x[n]=x[−n]∀nx[n] = x[-n] \\; \\forall n.\nA DT signal is odd if x[n]=−x[−n]∀nx[n] = -x[-n] \\; \\forall n.\nAny DT signal can be written in terms of an even and odd component x[n]=xe[n]+xo[n]x[n] = x_e[n] + x_o[n] where xe[n]=12{x[n]+x[−n]}xo[n]=12{x[n]−x[−n]}\\begin{array}{ll}\nx_e[n] &= \\frac{1}{2}\\left\\{x[n] + x[-n]\\right\\} \\\\\n& \\\\\nx_o[n] &= \\frac{1}{2}\\left\\{x[n] - x[-n]\\right\\}\n\\end{array}\nAnalogous to CT signals, the energy of a DT signal is Ex=limN→∞∑−NN|x[n]|2.E_x = \\lim_{N\\rightarrow\\infty} \\sum\\limits_{-N}^N \\lvert x[n]\\rvert^2 \\; .\nAnd the power of a DT signal is the energy averaged over an interval as that interval tends to infinity.\nPx=limN→∞12N+1∑−NN|x[n]|2.P_x = \\lim_{N\\rightarrow\\infty} \\frac{1}{2N+1} \\sum\\limits_{-N}^N \\lvert x[n]\\rvert^2 \\; .\nDT Signals with finite, non-zero energy and zero power are called energy signals. DT Signals with finite, non-zero power (and by implication infinite energy) are called power signals. These categories are non-exclusive, some signals are neither energy or power signals.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Discrete-Time Signals</span>"
    ]
  },
  {
    "objectID": "03-dt-signals.html#dt-unit-impulse-function",
    "href": "03-dt-signals.html#dt-unit-impulse-function",
    "title": "3  Discrete-Time Signals",
    "section": "3.4 DT Unit Impulse Function",
    "text": "3.4 DT Unit Impulse Function\nIn DT the unit impulse function, denoted δ[n]\\delta[n] is defined as δ[n]={1n=00else\\delta[n] = \\left\\{\n\\begin{array}{ll}\n  1 & n = 0\\\\\n  0 & \\text{else}\n\\end{array}\n\\right. Note this definition is straightforward compared to the CT impulse as there are no continuity issues and it is not defined in terms of a distribution. It is typically drawn as\n\n\nCode\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nmatplotlib.rcParams.update({'font.size': 12})\n\nn = np.linspace(-5, 5, 11);\nx = np.zeros(11)\nx[5] = 1\n\nf = plt.figure()\n\nplt.stem(n, x)\nplt.xlabel('$n$')\nplt.ylabel('$\\delta[n]$')\nplt.grid(True)\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3.1: Plot of discrete-time delta function.\n\n\n\n\n\nSome useful properties of the DT impulse function are:\n\nEnergy is 1: ∑n=−∞∞δ[n]=1\\sum\\limits_{n=-\\infty}^{\\infty} \\delta[n] = 1\nSampling: x[n]δ[n−n0]=x[n0]δ[n−n0]x[n]\\delta[n-n_0] = x[n_0]\\delta[n-n_0]\nSifting: ∑n=−∞∞x[n]δ[n−n0]=x[n0]\\sum\\limits_{n=-\\infty}^{\\infty} x[n]\\delta[n-n_0] = x[n_0]\n\nThe impulse can be defined in terms of the step: δ[n]=u[n]−u[n−1]\\delta[n] = u[n] - u[n-1] and vice-versa u[n]=∑m=−∞nδ[m]u[n] = \\sum\\limits_{m=-\\infty}^{n} \\delta[m] or u[n]=∑k=0∞δ[n−k]u[n] = \\sum\\limits_{k=0}^{\\infty} \\delta[n-k]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Discrete-Time Signals</span>"
    ]
  },
  {
    "objectID": "03-dt-signals.html#dt-complex-exponential",
    "href": "03-dt-signals.html#dt-complex-exponential",
    "title": "3  Discrete-Time Signals",
    "section": "3.5 DT Complex Exponential",
    "text": "3.5 DT Complex Exponential\nThe DT Complex Exponential is defined in a similar fashion the the CT version, but with some important differences. The general DT complex exponential is given by the expression: x[n]=Ceβnx[n] = Ce^{\\beta n} where in general C∈ℂC \\in \\mathbb{C} and β∈ℂ\\beta \\in \\mathbb{C}. It is sometimes convenient (for reasons we will see later) to write this as x[n]=Cαnx[n] = C \\alpha^n where α=ejθ\\alpha = e^{j\\theta} is a complex number α=cos(θ)+jsin(θ)\\alpha = \\cos(\\theta) + j\\sin(\\theta).\nWe now examine several special cases.\n\n3.5.1 DT Complex Exponential: real case\nLet CC and α\\alpha be real, then there are four intervals of interest:\n\nα&gt;1\\alpha &gt; 1\n0&lt;α&lt;10 &lt; \\alpha &lt; 1\n−1&lt;α&lt;0-1 &lt; \\alpha &lt; 0\nα&lt;−1\\alpha &lt; -1\n\nEach of these are shown in Figure 3.2.\n\n\nCode\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nn = np.linspace(-6, 6, 13);\n\nf = plt.figure()\n\nplt.subplot(2, 2, 1)\nalpha = 2\nplt.stem(n, np.power(alpha, n))\nplt.xlabel('$n$')\nplt.ylabel('$x[n]$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.subplot(2, 2, 2)\nalpha = 0.5\nplt.stem(n, np.power(alpha, n))\nplt.xlabel('$n$')\nplt.ylabel('$x[n]$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.subplot(2, 2, 3)\nalpha = -0.5\nplt.stem(n, np.power(alpha, n))\nplt.xlabel('$n$')\nplt.ylabel('$x[n]$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.subplot(2, 2, 4)\nalpha = -2\nplt.stem(n, np.power(alpha, n))\nplt.xlabel('$n$')\nplt.ylabel('$x[n]$')\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.tight_layout()\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3.2: DT Complex Exponential: real case, four intervals of interest.\n\n\n\n\n\n\n\n3.5.2 DT Complex Exponential: sinusoidal case\nLet C=1C = 1. When β\\beta is purely imaginary, β=jω0\\beta = j\\omega_0 x[n]=ejω0nx[n] = e^{j\\omega_0 n}\nAs in CT, by Euler’s identity: ejω0n=cos(ω0n)+jsin(ω0n)e^{j\\omega_0 n} = \\cos(\\omega_0 n) + j\\sin(\\omega_0 n) and ℜ(x[n])=cos(ω0n)=12(ejω0n+e−jω0n)\\Re(x[n]) = \\cos(\\omega_0 n) = \\frac{1}{2}\\left( e^{j\\omega_0 n} + e^{-j\\omega_0 n} \\right) ℑ(x[n])=sin(ω0n)=12j(ejω0n−e−jω0n)\\Im(x[n]) = \\sin(\\omega_0 n) = \\frac{1}{2j}\\left( e^{j\\omega_0 n} - e^{-j\\omega_0 n} \\right)\nThe energy and power are the same as for the CT complex sinusoid: Ex=∞E_x = \\infty and Px=1P_x = 1.\n\n\n3.5.3 DT Complex Exponential: sinusoidal case with phase shift\nThe general DT sinusoid is\nx[n]=Acos(ω0n+ϕ)x[n] = A\\cos(\\omega_0 n + \\phi)\n\nAA is called the amplitude\nϕ\\phi is called the phase shift\nω0\\omega_0 is now in radians (assuming nn is dimensionless)\n\n\n\nCode\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nn = np.linspace(-10, 10, 21);\nx = np.cos(2*np.pi/10*n + np.pi/8)\n\nf = plt.figure()\n\nplt.stem(n, x)\nplt.xlabel('$n$')\nplt.ylabel('$x[n]$')\nplt.grid(True)\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.tight_layout()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nFor CT sinusoids as ω0\\omega_0 increases the signal oscillates faster and faster. However for DT sinusoids there is a \"fastest\" oscillation.\nejω0n|ω0=π=ejπn=(−1)ne^{j\\omega_0 n}\\rvert_{\\omega_0 = \\pi} = e^{j\\pi n} = (-1)^n\n\n\nCode\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nn = np.linspace(-5, 5, 11);\nx = np.power(-1, n)\n\nf = plt.figure()\n\nplt.stem(n, x)\nplt.xlabel('$n$')\nplt.ylabel('$x[n]$')\nplt.grid(True)\nplt.autoscale(enable=True, axis='x', tight=True)\n\nplt.tight_layout()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n3.5.4 Properties of DT complex sinusoid\nIf we consider two frequencies: ω0\\omega_0 and ω0+2π\\omega_0+2\\pi. In the first case: x[n]=ejω0nx[n] = e^{j\\omega_0 n} In the second case: x[n]=ej(ω0+2π)n=ej2πn⏟always 1ejω0n=ejω0n\\begin{array}{ll}\nx[n] &= e^{j(\\omega_0+2\\pi) n} \\\\\n&= \\underbrace{e^{j2\\pi n}}_{\\text{always 1}}\\; e^{j\\omega_0 n} \\\\\n&= e^{j\\omega_0 n}\n\\end{array}\nThus the two are the same signal. This has important implications later in the course.\nAnother difference between CT and DT complex sinusoids is periodicity. Recall for a DT signal to be periodic with period NN x[n]=x[n+N]∀nx[n] = x[n+N] \\; \\forall n Substituting the complex sinusoid ejω0n=ejω0(n+N)=ejω0nejω0Ne^{j\\omega_0 n} = e^{j\\omega_0 (n+N)} = e^{j\\omega_0 n}e^{j\\omega_0 N} requires ejω0N=1e^{j\\omega_0 N} = 1, which implies ω0N\\omega_0 N is a multiple of 2π2\\pi: ω0N=2πmm=±1,±2,⋯\\omega_0 N = 2\\pi m \\;\\;\\; m = \\pm 1, \\pm 2, \\cdots or equivalently |ω0|2π=mN\\frac{|\\omega_0|}{2\\pi} = \\frac{m}{N} thus ω0\\omega_0 must be a rational multiple of π\\pi.\nTwo DT complex sinusoids are harmonics of one another is both are periodic in NN, i.e when\nxk(t)=ejk2πNnfork=0,±1,±2,⋯x_k(t) = e^{jk\\frac{2\\pi}{N} n} \\; \\text{for} \\; k = 0, \\pm 1, \\pm 2, \\cdots\nThis implies there are only NN distinct harmonics in DT.\n\n\n3.5.5 DT Complex Exponential: general case\nIn the general case we get a sinusoid signal modulated by an exponential. Let C=AejϕC = Ae^{j\\phi} and β=r+jω0\\beta = r + j\\omega_0, then x[n]=Ceβn=Aejϕe(r+jω0)nx[n] = C e^{\\beta n} =  Ae^{j\\phi} e^{(r+j\\omega_0)n} Expanding the terms and using Euler’s identity gives:\nx[n]=Aerncos(ω0n+ϕ)⏟ℜpart+jAernsin(ω0n+ϕ)⏟ℑpartx[n] = \\underbrace{Ae^{rn}\\cos(\\omega_0 n+\\phi)}_{\\Re \\text{part}} + j \\underbrace{Ae^{rn}\\sin(\\omega_0 n+\\phi)}_{\\Im \\text{part}} Each part is a real sinusoid whose amplitude is modulated by a real exponential.\nThe visualization of the general case is to view the signal x[n]x[n] as a vector rotating through fixed angles in the complex plane.\n\n\n\nThe DT complex sinusoid at a specific point in time.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Discrete-Time Signals</span>"
    ]
  },
  {
    "objectID": "04-ct-lccde.html",
    "href": "04-ct-lccde.html",
    "title": "4  CT Systems as Linear Constant Coefficient Differential Equations",
    "section": "",
    "text": "4.1 Solving Linear, Constant Coefficient Differential Equations\nRecall a system is a transformation of signals, turning the input signal into the output signal. While this might seem like a new concept to you, you already know something about them from your differential equations course, i.e. MATH 2214 and your circuits course.\nFor example, consider the following circuit:\nwhere the switch moves position at t=0t = 0. The governing equation for the circuit when t&lt;0t &lt; 0 is dVcdt(t)+1RCVc(t)=0\\frac{dV_c}{dt}(t) + \\frac{1}{RC}V_c(t) = 0 a homogeneous differential equation of first-order. From a DC analysis, the initial condition on the capacitor voltage is VC(0−)=0V_C(0^-) = 0, so there is no current flowing prior to t=0t = 0 and the solution is VC(t)=0V_C(t) = 0 for t&lt;0t &lt; 0.\nAfter the switch is thrown, the governing equation for the circuit when t≥0t \\geq 0 is dVcdt(t)+1RCVc(t)=1RC\\frac{dV_c}{dt}(t) + \\frac{1}{RC}V_c(t) = \\frac{1}{RC} Since the voltage across the capacitor cannot change instantaneously VC(0−)=VC(0+)=0V_C(0^-) = V_C(0^+) = 0, giving the auxillary condition necessary to solve this equation, which has the form VC(t)=A+Be−1RCtV_C(t) = A + Be^{-\\frac{1}{RC}t} Using the auxillary condition we find VC(0)=A+Be−1RC0=A+B=0 which implies B=−AV_C(0) = A + Be^{-\\frac{1}{RC}0} = A + B = 0 \\mbox{ which implies } B = -A Subsitution back into the differential equation and equating the coefficients gives A=1A = 1. Thus the voltage for t≥0t \\geq 0 is VC(t)=1−e−1RCtV_C(t) = 1 - e^{-\\frac{1}{RC}t}\nSuppose we consider the voltage after the switch as the input signal x(t)x(t) to the system composed of the series RC. As we have seen previously a mathematical model of the switch is the unit step x(t)=u(t)x(t) = u(t). Suppose we consider the capacitor voltage at the output of the system, so that y(t)=VC(t)y(t) = V_C(t). Then we can consider the system to be represented by the linear, constant-coefficient differential equation dydt(t)+1RCy(t)=1RCx(t)\\frac{dy}{dt}(t) + \\frac{1}{RC}y(t) = \\frac{1}{RC}x(t) where x(t)=u(t)x(t) = u(t) and the solution y(t)y(t) is the step response y(t)=(1−e−1RCt)u(t)y(t) = \\left(1 - e^{-\\frac{1}{RC}t}\\right)u(t)\nAs we will see later this representation of systems is central to the course, so we take some time here to review the solution of such equations.\nA linear, constant coefficient (LCC) differential equation is of the form a0y+a1dydt+a2d2ydt2+⋯+aNdNydtN=b0x+b1dxdt+b2d2xdt2+⋯+bMdMxdtMa_0\\, y + a_1\\, \\frac{dy}{dt} + a_2\\, \\frac{d^2y}{dt^2} + \\cdots + a_N\\, \\frac{d^Ny}{dt^N}  = b_0\\, x + b_1\\, \\frac{dx}{dt} + b_2\\, \\frac{d^2x}{dt^2} + \\cdots + b_M\\, \\frac{d^Mx}{dt^M} which can be written compactly as ∑k=0Nakdkydtk=∑k=0Mbkdkxdtk\\sum\\limits_{k = 0}^{N} a_k\\, \\frac{d^ky}{dt^k} = \\sum\\limits_{k = 0}^{M} b_k\\, \\frac{d^kx}{dt^k}\nIt is helpful to clean up this notation using the derivative operator Dn=dndtnD^n = \\frac{d^n}{dt^n}. For example D2y=d2ydt2D^2y = \\frac{d^2y}{dt^2} and D0y=yD^0 y= y. To give for form as ∑k=0NakDky=∑k=0MbkDkx\\sum\\limits_{k = 0}^{N} a_k\\, D^k y = \\sum\\limits_{k = 0}^{M} b_k\\, D^k x\nWe can factor out the derivative operators a0y+a1Dy+a2D2y+⋯+aNDNy=b0x+b1Dx+b2D2x+⋯+bMDMxa_0y + a_1Dy + a_2D^2y + \\cdots + a_ND^Ny  = b_0\\, x + b_1\\, Dx + b_2\\, D^2x + \\cdots + b_M\\, D^M x (a0+a1D+a2D2+⋯+aNDN)⏟Polynomial in D,Q(D)y=(b0+b1D+b2D2+⋯+bMDM)⏟Polynomial in D,P(D)x\\underbrace{\\left(a_0 + a_1D + a_2D^2 + \\cdots + a_ND^N\\right)}_{\\text{Polynomial in } D, Q(D)} y = \\underbrace{\\left(b_0 + b_1 D + b_2 D^2 + \\cdots + b_M D^M\\right)}_{\\text{Polynomial in } D, P(D)} x to give:\nQ(D)y=P(D)xQ(D)y = P(D)x You learned how to solve these in differential equations (Math 2214) as y(t)=yh(t)+yp(t)y(t) = y_\\text{h}(t) + y_\\text{p}(t)\nThe term yh(t)y_\\text{h}(t) is the solution of the homogeneous equation Q(D)y=0Q(D)y = 0 Given the N−1N-1 auxillary conditions y(t0)=y0y(t_0) = y_0, Dy(t0)=y1Dy(t_0) = y_1, D2y(t0)=y2D^2y(t_0) = y_2, up to DN−1y(t0)=yN−1D^{N-1}y(t_0) = y_{N-1}.\nThe term yp(t)y_\\text{p}(t) is the solution of the particular equation Q(D)y=P(D)xQ(D)y = P(D)x for a given x(t)x(t).\nRather than recapitulate the solution to yh(t)y_\\text{h}(t) and yp(t)y_\\text{p}(t) in the general case we focus on the homogeneous solution yh(t)y_\\text{h}(t) only. The reason is that we will use the homogeneous solution to find the impulse response below and take a different approach to solving the general case for an arbitrary input using the impulse response and convolution (next week).\nTo solve the homogenous system:\nStep 1: Find the characteristic equation by replacing the derivative operators by powers of an arbitrary complex variable ss. Q(D)=a0+a1D+a2D2+⋯+aNDNQ(D) = a_0 + a_1D + a_2D^2 + \\cdots + a_ND^N becomes Q(s)=a0+a1s+a2s2+⋯+aNsNQ(s) = a_0 + a_1s + a_2s^2 + \\cdots + a_Ns^N a polynomial in ss with NN roots sis_i for i=1,2,⋯,Ni = 1, 2, \\cdots, N such that (s−s1)(s−s2)⋯(s−sN)=0(s - s_1)(s-s_2)\\cdots(s-s_N) = 0\nStep 2: Select the form of the solution, a sum of terms corresponding to the roots of the characteristic equation.\nStep 3: Solve for the unknown constants in the solution using the auxillary conditions.\nWe now examine two common special cases, when N=1N=1 (first-order) and when N=2N=2 (second-order).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>CT Systems as Linear Constant Coefficient Differential Equations</span>"
    ]
  },
  {
    "objectID": "04-ct-lccde.html#solving-linear-constant-coefficient-differential-equations",
    "href": "04-ct-lccde.html#solving-linear-constant-coefficient-differential-equations",
    "title": "4  CT Systems as Linear Constant Coefficient Differential Equations",
    "section": "",
    "text": "For a real root s1∈ℝs_1\\in \\mathbb{R} the term is of the form C1es1t.C_1 e^{s_1 t}.\nFor a pair of complex roots (they will always be in pairs) s1,2=a±jbs_{1,2} = a \\pm jb the term is of the form C1es1t+C2es2t=eat(C3cos(bt)+C4sin(bt))=C5eatcos(bt+C6).C_1 e^{s_1 t} + C_2 e^{s_2 t} = e^{a t}\\left(C_3\\cos(bt) + C_4\\sin(bt)\\right) = C_5 e^{a t}\\cos(bt + C_6).\nFor a repeated root s1s_1, repeated rr times, the term is of the form es1t(C0+C1t+⋯+Cr−1tr−1).e^{s_1 t} (C_0 + C_1 t + \\cdots + C_{r-1} t^{r-1}).\n\n\n\n\n4.1.1 First-Order Homogeneous LCCDE\nConsider the first order homogeneous differential equation dydt(t)+ay(t)=0 for a∈ℝ\\frac{dy}{dt}(t) + ay(t) = 0 \\mbox{ for } a \\in \\mathbb{R} The characteristic equation is given by s+a=0s + a = 0 which has a single root s1=−as_1 = -a. The solution is of the form y(t)=Ces1t=Ce−aty(t) = Ce^{s_1 t} = Ce^{-a t} where the constant CC is found using the auxillary condition y(t0)=y0y(t_0) = y_0.\n\n\nExample\n\n\nConsider the homogeneous equation dydt(t)+3y(t)=0 where y(0)=10\\frac{dy}{dt}(t) + 3y(t) = 0 \\mbox{ where } y(0) = 10 The solution is y(t)=Ce−3ty(t) = Ce^{-3 t} To find CC we use the auxillary condition y(0)=Ce−3⋅0=C=10y(0) = Ce^{-3 \\cdot 0} = C = 10 and the final solution is y(t)=10e−3ty(t) = 10e^{-3 t}\n\n\n\n\n4.1.2 Second-Order Homogeneous LCCDE\nConsider the second-order homogeneous differential equation d2ydt2(t)+adydt(t)+by(t)=0 for a,b∈ℝ\\frac{d^2y}{dt^2}(t) + a\\frac{dy}{dt}(t) + by(t) = 0 \\mbox{ for } a,b \\in \\mathbb{R} The characteristic equation is given by s2+as+b=0s^2 + as + b = 0\nLet’s look at several examples to illustrate the functional forms.\n\n\nExample\n\n\nd2ydt2(t)+7dydt(t)+10y(t)=0\\frac{d^2y}{dt^2}(t) + 7\\frac{dy}{dt}(t) + 10y(t) = 0 The characteristic equation is given by s2+7s+10=0s^2 + 7s + 10 = 0 which has roots s1=−2s_1 = -2 and s2=−5s_2 = -5. Thus the form of the solution is y(t)=C1e−2t+C2e−5ty(t) = C_1e^{-2t} + C_2e^{-5t}\n\n\n\n\nExample\n\n\nd2ydt2(t)+2dydt(t)+5y(t)=0\\frac{d^2y}{dt^2}(t) + 2\\frac{dy}{dt}(t) + 5y(t) = 0 The characteristic equation is given by s2+2s+5=0s^2 + 2s + 5 = 0 which has complex roots s1=−1+j2s_1 = -1+j2 and s1=−1−j2s_1 = -1-j2. Thus the form of the solution is y(t)=e−t(C1cos(2t)+C2sin(2t))y(t) = e^{-t}\\left(C_1\\cos(2t) + C_2\\sin(2t)\\right)\n\n\n\n\nExample\n\n\nd2ydt2(t)+2dydt(t)+y(t)=0\\frac{d^2y}{dt^2}(t) + 2\\frac{dy}{dt}(t) + y(t) = 0 The characteristic equation is given by s2+2s+1=0s^2 + 2s + 1 = 0 which has a root s1=−1s_1 = -1 repeated r=2r=2 times. Thus the form of the solution is y(t)=e−t(C1+C2t)y(t) = e^{-t}\\left(C_1 + C_2t\\right)\n\n\nIn each of the above cases the constants, C1C_1 and C2C_2, are found using the auxillary conditions y(t0)y(t_0) and y′(t0)y\\prime(t_0).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>CT Systems as Linear Constant Coefficient Differential Equations</span>"
    ]
  },
  {
    "objectID": "04-ct-lccde.html#finding-the-impulse-response-of-a-system-described-by-a-lccde",
    "href": "04-ct-lccde.html#finding-the-impulse-response-of-a-system-described-by-a-lccde",
    "title": "4  CT Systems as Linear Constant Coefficient Differential Equations",
    "section": "4.2 Finding the impulse response of a system described by a LCCDE",
    "text": "4.2 Finding the impulse response of a system described by a LCCDE\nAs we will see next week an important response of a system is the one that corresponds to an impulse input, i.e. the impulse response y(t)=h(t)y(t) = h(t) when x(t)=δ(t)x(t) = \\delta(t). Thus we focus here on a recipe for solving LCCDEs for this special case when M≤NM \\leq N. We will skip the derivation of why this works.\nOur goal is to find the solution to Q(D)y=P(D)xQ(D)y = P(D)x when x(t)=δ(t)x(t)=\\delta(t).\nStep 1: Rearrange the LCCDE so that aN=1a_N = 1, i.e. divide through by aNa_N to put it into a standard form.\nStep 2: Let yh(t)y_h(t) be the homogeneous solution to Q(D)yh=0Q(D)y_h = 0 for auxillary conditions DN−1yh(0+)=1,DN−2yh(0+)=0,etc.yh(0+)=0D^{N-1}y_h(0^+) = 1 \\; , \\; D^{N-2}y_h(0^+) = 0 \\; , \\; \\text{etc.} \\; y_h(0^+) = 0\nStep 3: Assume a form for h(t)h(t) given by: h(t)=bNδ(t)⏟=0 unless N=M+[P(D)yh]⏟apply P(D) to yn(t)u(t)h(t) = \\underbrace{b_N\\delta(t)}_{=0 \\text{ unless } N=M} + \\underbrace{\\left[ P(D)y_h\\right]}_{\\text{apply } P(D) \\text{ to } y_n(t)}u(t)\nRecall from above the homogeneous solution depends on the roots of the characteristic equation Q(D)=0Q(D) = 0.\n\nroots are either real, or\nroots occur in complex conjugate pairs, or\nrepeated roots.\n\n\n\nExample\n\n\nFind the impulse response of the LCCDE 2dydt(t)+2y(t)=2x(t)2\\frac{dy}{dt}(t) + 2y(t) = 2x(t) In the standard for the LCCDE is dydt(t)+y(t)=x(t)\\frac{dy}{dt}(t) + y(t) = x(t) The characteristic equation is given by s+1=0s + 1 = 0 which has a single root s1=−1s_1 = -1. The solution is of the form yh(t)=Ce−ty_h(t) = Ce^{-t} with the special auxillary condition y(0)=1y(0) = 1, so that yh(t)=e−ty_h(t) = e^{-t} Since P(D)=1P(D) = 1 and N=1≠M=0N = 1 \\neq M = 0 the impulse response is h(t)=bNδ(t)⏟=0+[P(D)⏟1yh(t)]u(t)=e−tu(t)h(t) = \\underbrace{b_N\\delta(t)}_{=0} + \\left[ \\underbrace{P(D)}_{1}y_h(t)\\right]u(t) = e^{-t}u(t)\n\n\n\n\nExample\n\n\nFind the impulse response of the LCCDE dydt(t)+y(t)=dxdt(t)+x(t)\\frac{dy}{dt}(t) + y(t) = \\frac{dx}{dt}(t) + x(t) It is already in the standard form. The homogeneous solution is the same as in Example 1, yh(t)=e−ty_h(t) = e^{-t} however now M=N=1M = N = 1 with b1=1b_1 = 1 and P(D)=D+1P(D) = D+1. Thus, the impulse response is h(t)=bN⏟=1δ(t)+[P(D)⏟D+1yh(t)]u(t)=δ(t)+{[D+1]e−t}u(t)=δ(t)+[−e−t+e−t]u(t)=δ(t)h(t) = \\underbrace{b_N}_{=1}\\delta(t) + \\left[ \\underbrace{P(D)}_{D+1}y_h(t)\\right]u(t) = \\delta(t) + \\left\\{[D+1]e^{-t}\\right\\}u(t) = \\delta(t) + [- e^{-t} + e^{-t}]u(t) = \\delta(t)\n\n\n\n\nExample\n\n\nFind the impulse response of the LCCDE d2ydt2(t)+7dydty(t)+10y(t)=x(t)\\frac{d^2y}{dt^2}(t) + 7\\frac{dy}{dt}y(t) + 10y(t) = x(t) It is already in the standard form. The characteristic equation is given by s2+7s+10=0s^2 + 7s + 10 = 0 which has roots s1=−2s_1 = -2 and s2=−5s_2 = -5. Thus the form of the solution is yh(t)=C1e−2t+C2e−5ty_h(t) = C_1e^{-2t} + C_2e^{-5t} The special auxillary conditions are yh(0)=0y_h(0) = 0 and yh′(0)=1y^\\prime_h(0) = 1. Using these conditions yh(0)=C1e−2t+C2e−5t|t=0=C1+C2=0y_h(0) = C_1e^{-2t} + C_2e^{-5t} |_{t = 0} = C_1 + C_2 = 0 yh′(0)=−2C1e−2t−5C2e−5t|t=0=−2C1−5C2=1y^\\prime_h(0) = -2C_1e^{-2t} - 5C_2e^{-5t} |_{t = 0} = -2C_1 -5C_2 = 1 Solving for the constants gives C1=13C_1 = \\frac{1}{3} and C2=−13C_2 = -\\frac{1}{3}. Since P(D)=1P(D) = 1 and N=2≠M=0N = 2 \\neq M = 0 the impulse response is h(t)=bNδ(t)⏟=0+[P(D)⏟1yh(t)]u(t)=13e−2tu(t)−13e−5tu(t)h(t) = \\underbrace{b_N\\delta(t)}_{=0} + \\left[ \\underbrace{P(D)}_{1}y_h(t)\\right]u(t) = \\frac{1}{3} e^{-2t}u(t) - \\frac{1}{3} e^{-5t}u(t)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>CT Systems as Linear Constant Coefficient Differential Equations</span>"
    ]
  },
  {
    "objectID": "05-dt-lccde.html",
    "href": "05-dt-lccde.html",
    "title": "5  DT systems as linear constant coefficient difference equations",
    "section": "",
    "text": "5.1 Definition of linear constant coefficient difference equation\nA difference equation is a relation among combinations of two DT functions and shifted versions of them. Similar to differential equations where the solution is a CT function, the solution to a difference equation is a DT function. For example: y[n+1]+12y[n]=x[n]y[n+1] + \\frac{1}{2}y[n] = x[n] is a first order, linear, constant-coefficient difference equation. Given x[n]x[n] the solution is a function y[n]y[n]. We can view this as a representation of a DT system, where x[n]x[n] is the input signal and y[n]y[n] is the output.\nThere is a parallel theory to differential equations for solving difference equations. However in this lecture we will focus specifically on the iterative solution of linear, constant-coefficient difference equations and the case when the input is a delta function, as this is all we need for this course.\nA linear, constant-coefficient, difference equation (LCCDE) comes in one of two forms.\nThe order of the system is given by NN. The delay and advance forms are equivalent because the equation holds for any nn, and we can move back and forth between them as needed by a constant index-shift.\nIt will be convenient to define the operator EmE^m as shifting a DT function by positive mm, i.e. Emx[n]=x[n+m]E^m x[n] = x[n+m], and the operator DmD^m as shifting a DT function by negative mm, i.e. Dmx[n]=x[n−m]D^m x[n] = x[n-m]. These are called the advance and delay operators respectively. Then, the advance form of the difference equation using this operator notation is a0y[n+N]+a1y[n+N−1]+⋯aNy[n]=b0x[n+N]+⋯bMx[n+N−M]a_0y[n+N] + a_1y[n+N-1] + \\cdots a_N y[n] = b_0 x[n+N] + \\cdots b_Mx[n+N-M] a0ENy+a1EN−1y+⋯aNy=b0ENx+⋯bMEN−Mxa_0 E^Ny + a_1E^{N-1}y + \\cdots a_N y = b_0 E^{N}x + \\cdots b_M E^{N-M}x Factoring out the advance operators gives (a0EN+a1EN−1+⋯aN)⏟Q(E)y=(b0EN+⋯bMEN−M)⏟P(E)x\\underbrace{\\left(a_0E^N + a_1E^{N-1} + \\cdots a_N\\right)}_{Q(E)} y = \\underbrace{\\left(b_0 E^{N} + \\cdots b_M E^{N-M}\\right)}_{P(E)} x or Q(E)y[n]=P(E)x[n]Q(E)y[n] = P(E)x[n]\nSimilarly, the delay form of the difference equation using this operator notation is a0y[n]+a1y[n−1]+⋯aNy[n−N]=b0x[n]+⋯bMx[n−M]a_0y[n] + a_1y[n-1] + \\cdots a_N y[n-N] = b_0 x[n] + \\cdots b_Mx[n-M] a0y[n]+a1Dy+⋯aNDNy=b0x+⋯bMDMxa_0y[n] + a_1 Dy + \\cdots a_N D^N y = b_0 x + \\cdots b_MD^M x Note: The DT delay operator DD is similar, but not identical to the derivative operator DD in CT.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DT systems as linear constant coefficient difference equations</span>"
    ]
  },
  {
    "objectID": "05-dt-lccde.html#definition-of-linear-constant-coefficient-difference-equation",
    "href": "05-dt-lccde.html#definition-of-linear-constant-coefficient-difference-equation",
    "title": "5  DT systems as linear constant coefficient difference equations",
    "section": "",
    "text": "Delay form. ∑k=0Naky[n−k]=∑k=0Mbkx[n−k]\\sum\\limits_{k = 0}^N a_k y[n-k] = \\sum\\limits_{k = 0}^M b_k x[n-k] or a0y[n]+a1y[n−1]+⋯aNy[n−N]=b0x[n]+⋯bMx[n−M]a_0y[n] + a_1y[n-1] + \\cdots a_N y[n-N] = b_0 x[n] + \\cdots b_Mx[n-M]\nAdvance form. Let n→n+Nn\\rightarrow n+N, then the delay form becomes ∑k=0Naky[n+N−k]=∑k=0Mbkx[n+N−k]\\sum\\limits_{k = 0}^N a_k y[n+N-k] = \\sum\\limits_{k = 0}^M b_k x[n+N-k] or a0y[n+N]+a1y[n+N−1]+⋯aNy[n]=b0x[n+N]+⋯bMx[n+N−M]a_0y[n+N] + a_1y[n+N-1] + \\cdots a_N y[n] = b_0 x[n+N] + \\cdots b_Mx[n+N-M]\n\n\n\n\nExample\n\n\nThe delay form is a0y[n]+a1y[n−1]+a2y[n−2]=b0x[n]+b1x[n−1]a_0y[n] + a_1 y[n-1] + a_2 y[n-2] = b_0 x[n] + b_1 x[n-1] Replacing n→n+2n \\rightarrow n+2, the advance form is a0y[n+2]+a1y[n+1]+a2y[n]=b0x[n+2]+b1x[n+1]a_0 y[n+2] + a_1 y[n+1] + a_2 y[n] = b_0 x[n+2] + b_1 x[n+1]\n\n\n\n\n\n\nExample\n\n\nConsider the difference equation 3y[n+1]+4y[n]+5y[n−1]=2x[n+1]3y[n+1] + 4y[n] + 5y[n-1] = 2x[n+1] The advance form would be: 3y[n+2]+4y[n+1]+5y[n]=2x[n+2]3y[n+2] + 4y[n+1] + 5y[n] = 2x[n+2] or using the advance operator (3E2+4E+5)y=2E2x\\left(3E^2 + 4E + 5\\right)y = 2E^2x with Q(E)=3E2+4E+5Q(E) = 3E^2 + 4E + 5 and P(E)=2E2P(E) = 2E^2.\nThe delay form would be: 3y[n]+4y[n−1]+5y[n−2]=2x[n]3y[n] + 4y[n-1] + 5y[n-2] = 2x[n] or using the delay operator (5D2+4D+3)y=2x\\left(5D^2 + 4D + 3\\right)y = 2x with Q(D)=5D2+4D+3Q(D) = 5D^2 + 4D + 3 and P(D)=2P(D) = 2.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DT systems as linear constant coefficient difference equations</span>"
    ]
  },
  {
    "objectID": "05-dt-lccde.html#iterative-solution-of-lccdes",
    "href": "05-dt-lccde.html#iterative-solution-of-lccdes",
    "title": "5  DT systems as linear constant coefficient difference equations",
    "section": "5.2 Iterative solution of LCCDEs",
    "text": "5.2 Iterative solution of LCCDEs\nDifference equations are different (pun!) from differential equations in that they can be solved by manually running the equation forward using previous values of the output and current and previous values of the input, given some initial conditions. This is called an iterative solution for this reason.\nTo perform an iterative solution we need the difference equation in delay form a0y[n]+a1y[n−1]+⋯aNy[n−N]=b0x[n]+⋯bMx[n−M]a_0y[n] + a_1y[n-1] + \\cdots a_N y[n-N] = b_0 x[n] + \\cdots b_Mx[n-M] We then solve for the current output y[n]y[n] y[n]=−(a1a0y[n−1]+⋯aNa0y[n−N])+b0a0x[n]+⋯bMa0x[n−M]y[n] =  - \\left(\\frac{a_1}{a_0}y[n-1] + \\cdots \\frac{a_N}{a_0} y[n-N]\\right) + \\frac{b_0}{a_0} x[n] + \\cdots \\frac{b_M}{a_0}x[n-M]\nNow lets examine what this expression says in words. To compute the current output y[n]y[n] we need the value of the previous N−1N-1 outputs, the value of the current input x[n]x[n] and M−1M-1 previous inputs (and the coefficients). Then we can compute the next output y[n+1]y[n+1] by adding the previous computation result for y[n]y[n] to our list of things to remember, and forgetting one previous value of yy. This can continue as long as we like.\n\n\nExample\n\n\nConsider the first-order difference equation y[n+1]+y[n]=x[n+1]y[n+1] + y[n] = x[n+1] where y[−1]=1y[-1] = 1 and x[n]=u[n]x[n] = u[n]. We first convert this to delay form y[n]=−y[n−1]+x[n].y[n] = -y[n-1] + x[n]\\; . Then we can compute y[0]y[0] as y[0]=−y[−1]+x[0]=−1+1=0y[0] = -y[-1] + x[0] = -1 + 1 = 0 and continuing\ny[1]=−y[0]+x[1]=0+1=1y[2]=−y[1]+x[2]=−1+1=0y[3]=−y[2]+x[3]=0+1=1etc.\\begin{aligned}\n  y[1] &= -y[0] + x[1] = 0 + 1 = 1\\\\\n  y[2] &= -y[1] + x[2] = -1 + 1 = 0\\\\\n  y[3] &= -y[2] + x[3] = 0 + 1 = 1\\\\\n  \\mbox{etc.}\n  \n\\end{aligned}\nWe can see that this will continue to give the alternating sequence 1,0,1,0,1,⋯1,0,1,0,1,\\cdots.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DT systems as linear constant coefficient difference equations</span>"
    ]
  },
  {
    "objectID": "05-dt-lccde.html#solution-of-the-homogeneous-lccde",
    "href": "05-dt-lccde.html#solution-of-the-homogeneous-lccde",
    "title": "5  DT systems as linear constant coefficient difference equations",
    "section": "5.3 Solution of the homogeneous LCCDE",
    "text": "5.3 Solution of the homogeneous LCCDE\nNote the iterative solution does not give us (directly) and analytical expression for the output at arbitrary nn. We have to start at the initial conditions and compute our way up to nn. We now consider an analytical solution when the input is zero, the solution to the homogeneous difference equation Q(E)y=a0y[n+N]+a1y[n+N−1]+⋯aNy[n]=0.Q(E)\\, y = a_0y[n+N] + a_1y[n+N-1] + \\cdots a_N y[n] = 0 \\; . given NN sequential auxiliary conditions on yy.\nSimilar to differential equations, the homogeneous solution depends on the roots of the characteristic equation Q(E)=0Q(E)=0 whose roots are either real or occur in complex conjugate pairs. Let λi\\lambda_i be the ii-th root of Q(E)=0Q(E) = 0, then the solution is of the form y[n]=∑i=1NCiλiny[n] = \\sum\\limits_{i=1}^N C_i \\lambda_i^{n} where the parameters CiC_i are determined from the auxiliary conditions.\nFor a real system (when the coefficients of the difference equation are real) and when the roots are complex λ1,2=|λ|e±jβ\\lambda_{1,2} = |\\lambda|e^{\\pm j\\beta}, it is cleaner to assume a form for those terms as y[n]=C|λ|ncos(βn+θ)y[n] = C |\\lambda|^n\\cos(\\beta n + \\theta) for constants CC and θ\\theta.\n\n\nExample\n\n\nFind the solution to the first-order homogeneous LCCDE y[n+1]+12y[n]=0 with y[0]=5.y[n+1] + \\frac{1}{2}y[n] = 0 \\mbox{ with } y[0] = 5 \\; . Note Q(E)=E+12Q(E) = E + \\frac{1}{2} has a single root λ1=−12\\lambda_1 = -\\frac{1}{2}. Thus the solution is of the form y[n]=C(−12)ny[n] = C\\left( -\\frac{1}{2}\\right)^n where the parameter CC is found using y[0]=C=5y[0] = C = 5 to give the final solution y[n]=5(−12)ny[n] = 5\\left( -\\frac{1}{2}\\right)^n\n\n\n\n\nExample\n\n\nFind the solution to the second-order homogeneous LCCDE y[n+2]+y[n+1]+12y[n]=0 with y[0]=1 and y[1]=0.y[n+2] + y[n+1] + \\frac{1}{2}y[n] = 0 \\mbox{ with } y[0] = 1 \\mbox{ and } y[1] = 0\\; . Note Q(E)=E2+E+12Q(E) = E^2 + E + \\frac{1}{2} has a pair of complex roots λ1,2=−12±j12\\lambda_{1,2} = -\\frac{1}{2} \\pm j\\frac{1}{2}. Thus the solution is of the form y[n]=C|12|ncos(3π4n+θ)y[n] = C \\left|\\frac{1}{\\sqrt{2}}\\right|^n\\cos\\left(\\frac{3\\pi}{4} n + \\theta\\right) where the parameters are found using y[0]=Ccos(θ)=1y[0] = C\\cos\\left(\\theta\\right) = 1 y[1]=C12cos(3π4+θ)=0y[1] = C\\frac{1}{\\sqrt{2}}\\cos\\left(\\frac{3\\pi}{4} + \\theta\\right) = 0 This is true when C=2 and θ=−π4+2πmC = \\sqrt{2} \\mbox{ and } \\theta = -\\frac{\\pi}{4} + 2\\pi m for any m∈ℤm\\in \\mathbb{Z} since cos\\cos is periodic in 2π2\\pi. A final solution is then y[n]=2|12|ncos(3π4n−π4)y[n] = \\sqrt{2} \\left|\\frac{1}{\\sqrt{2}}\\right|^n\\cos\\left(\\frac{3\\pi}{4} n - \\frac{\\pi}{4}\\right)\n\n\nSee the appendix for a general technique to solve for these constants.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DT systems as linear constant coefficient difference equations</span>"
    ]
  },
  {
    "objectID": "05-dt-lccde.html#impulse-response-from-lccde",
    "href": "05-dt-lccde.html#impulse-response-from-lccde",
    "title": "5  DT systems as linear constant coefficient difference equations",
    "section": "5.4 Impulse response from LCCDE",
    "text": "5.4 Impulse response from LCCDE\nToday our goal is to find the solution to Q(E)y=P(E)xQ(E)y=P(E)x when x[n]=δ[n]x[n] = \\delta[n] assuming y[n]=0y[n] = 0 for n&lt;0n &lt; 0, giving the impulse response y[n]=h[n]y[n] = h[n]. We skip the derivation here and just give a procedure.\nStep 1: Let yhy_h be the homogeneous solution to Q(E)yh=0Q(E)y_h=0 for n&gt;Nn &gt; N.\nStep 2: Assume a form for h[n]h[n] given by h[n]=bNaNδ[n]+yh[n]u[n]h[n] = \\frac{b_N}{a_N}\\delta[n] + y_h[n]u[n]\nStep 3: Using the iterative procedure above find the NN auxiliary conditions we need by,\n\nfirst, rewrite the equation in delay form and solve for y[n]y[n],\nthen let x[n]=δ[n]x[n] = \\delta[n] and manually compute h[0]h[0] assuming h[n]=0h[n] = 0 for n&lt;0n &lt; 0,\nrepeating the previous step for h[1]h[1], continuing up to h[N−1]h[N-1].\n\nStep 4: Using the auxillary conditions in step 3, solve for the constants in the solution h[n]h[n] from step 2.\n\n\nExample\n\n\nFind the impulse response of the system given by y[n+2]−14y[n+1]−18y[n]=2x[n+1]y[n+2] -\\frac{1}{4}y[n+1] -\\frac{1}{8}y[n]= 2x[n+1]\nFor step 1 we solve the equation yh[n+2]−14yh[n+1]−18yh[n]=0y_h[n+2] -\\frac{1}{4}y_h[n+1] -\\frac{1}{8}y_h[n] = 0 which is of the form yh[n]=C1(−14)n+C2(12)ny_h[n] = C_1 \\left( -\\frac{1}{4}\\right)^n + C_2 \\left( \\frac{1}{2}\\right)^n since the roots of Q(E)=E2−14E−18Q(E) = E^2 - \\frac{1}{4}E - \\frac{1}{8} are −14-\\frac{1}{4} and 12\\frac{1}{2}.\nFor step 3, we find the auxiliary conditions needed to find C1C_1 and C2C_2 by rewriting the original equation in delay form and solving for y[0]y[0] and y[1]y[1] when x[n]=δ[n]x[n] = \\delta[n]. y[n]=14y[n−1]+18y[n−2]+2x[n−1]y[n] = \\frac{1}{4}y[n-1] + \\frac{1}{8}y[n-2] + 2x[n-1] Let x[n]=δ[n]x[n] = \\delta[n] and manually compute y[0]y[0] assuming y[n]=0y[n] = 0 for n&lt;0n &lt; 0 y[0]=14y[0−1]⏟0+18y[0−2]⏟0+2δ[0−1]⏟0=0y[0] = \\frac{1}{4}\\underbrace{y[0-1]}_{0} + \\frac{1}{8}\\underbrace{y[0-2]}_{0} + 2\\underbrace{\\delta[0-1]}_{0} = 0 Repeat for y[1]y[1] y[1]=14y[1−1]⏟0+18y[1−2]⏟0+2δ[1−1]⏟1=2y[1] = \\frac{1}{4}\\underbrace{y[1-1]}_{0} + \\frac{1}{8}\\underbrace{y[1-2]}_{0} + 2\\underbrace{\\delta[1-1]}_{1} = 2 Now we find the constants using step 4 h[0]=C1+C2=0h[0] = C_1  + C_2  = 0 h[1]=C1(−14)+C2(12)=2h[1] = C_1 \\left( -\\frac{1}{4}\\right) + C_2 \\left( \\frac{1}{2}\\right) = 2 which gives C1=−83C_1 = -\\frac{8}{3} and C2=83C_2 = \\frac{8}{3}. Thus the final impulse response is h[n]=bNaNδ[n]+yh[n]u[n]=−83(−14)nu[n]+83(12)nu[n]h[n] = \\frac{b_N}{a_N}\\delta[n] + y_h[n]u[n] = -\\frac{8}{3}\\left( -\\frac{1}{4}\\right)^nu[n] + \\frac{8}{3}\\left( \\frac{1}{2}\\right)^n u[n] since bN=0b_N = 0.\n\n\nNote we can confirm our closed-form result in the previous example, for a few values of nn, by iteratively solving the difference equation h[0]=14h[0−1]⏟0+18h[0−2]⏟0+2δ[0−1]⏟0=0h[0] = \\frac{1}{4}\\underbrace{h[0-1]}_{0} + \\frac{1}{8}\\underbrace{h[0-2]}_{0} + 2\\underbrace{\\delta[0-1]}_{0} = 0 h[1]=14h[1−1]⏟0+18h[1−2]⏟0+2δ[1−1]⏟1=2h[1] = \\frac{1}{4}\\underbrace{h[1-1]}_{0} + \\frac{1}{8}\\underbrace{h[1-2]}_{0} + 2\\underbrace{\\delta[1-1]}_{1} = 2 h[2]=14h[2−1]⏟2+18h[2−2]⏟0+2δ[2−1]⏟0=12h[2] = \\frac{1}{4}\\underbrace{h[2-1]}_{2} + \\frac{1}{8}\\underbrace{h[2-2]}_{0} + 2\\underbrace{\\delta[2-1]}_{0} = \\frac{1}{2} h[3]=14h[3−1]⏟12+18h[3−2]⏟2+2δ[2−1]⏟0=38h[3] = \\frac{1}{4}\\underbrace{h[3-1]}_{\\frac{1}{2}} + \\frac{1}{8}\\underbrace{h[3-2]}_{2} + 2\\underbrace{\\delta[2-1]}_{0} = \\frac{3}{8} and comparing to our closed-form solution a the same values of nn h[0]=−83+83=0h[0] = -\\frac{8}{3} + \\frac{8}{3} = 0 h[1]=−83(−14)+83(12)=2h[1] = -\\frac{8}{3}\\left( -\\frac{1}{4}\\right) + \\frac{8}{3}\\left( \\frac{1}{2}\\right) = 2 h[2]=−83(−14)2+83(12)2=12h[2] = -\\frac{8}{3}\\left( -\\frac{1}{4}\\right)^2 + \\frac{8}{3}\\left( \\frac{1}{2}\\right)^2 = \\frac{1}{2} h[3]=−83(−14)3+83(12)3=38h[3] = -\\frac{8}{3}\\left( -\\frac{1}{4}\\right)^3 + \\frac{8}{3}\\left( \\frac{1}{2}\\right)^3 = \\frac{3}{8}\n\n\nExample\n\n\nFind the impulse response of the system given by y[n+1]−12y[n]=x[n+1]+x[n]y[n+1] - \\frac{1}{2}y[n] = x[n+1] + x[n]\nIn step 1 we note the solution to Q(E)y[n]=0Q(E)y[n] = 0 is of the form yh[n]=C(12)ny_h[n] = C\\left( \\frac{1}{2}\\right)^n From step 2 we note bN=1b_N = 1 and aN=−12a_N = -\\frac{1}{2}, so that h[n]=−2δ[n]+C(12)nu[n]h[n] = -2\\delta[n]  +  C\\left( \\frac{1}{2}\\right)^n\\, u[n] In step 3 we manually find h[0]h[0]\ny[n]=12y[n−1]+x[n]+x[n−1]h[n]=12y[n−1]+δ[n]+δ[n−1]h[0]=0+1+0=1\\begin{aligned}\n    y[n] &= \\frac{1}{2}y[n-1] + x[n] + x[n-1]\\\\\n    h[n] &= \\frac{1}{2}y[n-1] + \\delta[n] + \\delta[n-1]\\\\\n    h[0] &= 0 + 1 + 0 = 1\n  \n\\end{aligned}\nAnd in step 4 we solve for CC h[0]=−2+C=1 implies C=3h[0] = -2  +  C = 1 \\mbox{ implies } C = 3 to give h[n]=−2δ[n]+3(12)nu[n]h[n] = -2\\delta[n]  +  3\\left( \\frac{1}{2}\\right)^n\\, u[n]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DT systems as linear constant coefficient difference equations</span>"
    ]
  }
]